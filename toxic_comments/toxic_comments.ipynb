{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Лемматизация-и-удаление-стоп-слов\" data-toc-modified-id=\"Лемматизация-и-удаление-стоп-слов-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Лемматизация и удаление стоп-слов</a></span></li><li><span><a href=\"#Разделение-данных-на-выборки\" data-toc-modified-id=\"Разделение-данных-на-выборки-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Разделение данных на выборки</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>TF-IDF</a></span></li><li><span><a href=\"#Word2vec\" data-toc-modified-id=\"Word2vec-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Word2vec</a></span></li><li><span><a href=\"#BERT.-Создание-эмбеддингов\" data-toc-modified-id=\"BERT.-Создание-эмбеддингов-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>BERT. Создание эмбеддингов</a></span></li><li><span><a href=\"#Подбор-гиперпараметров\" data-toc-modified-id=\"Подбор-гиперпараметров-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Подбор гиперпараметров</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#TFIDF\" data-toc-modified-id=\"TFIDF-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>TFIDF</a></span></li><li><span><a href=\"#Word2vec\" data-toc-modified-id=\"Word2vec-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Word2vec</a></span></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>BERT</a></span></li></ul></li><li><span><a href=\"#Проверка-на-тесте-лучшей-модели-и-подхода\" data-toc-modified-id=\"Проверка-на-тесте-лучшей-модели-и-подхода-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Проверка на тесте лучшей модели и подхода</a></span></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>BERT</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификатор токсичности комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (1.23.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: jinja2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: setuptools in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/torch/cuda/__init__.py:529: UserWarning: HIP initialization: Unexpected error from hipGetDeviceCount(). Did you run some cuda functions before calling NumHipDevices() that might have already set an error? Error 101: hipErrorInvalidDevice (Triggered internally at ../c10/hip/HIPFunctions.cpp:110.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.23.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: jinja2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: setuptools in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (65.5.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: optuna in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (3.0.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (1.4.44)\n",
      "Requirement already satisfied: cliff in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: tqdm in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: colorlog in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (0.9.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (4.13.0)\n",
      "Requirement already satisfied: numpy in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (1.23.4)\n",
      "Requirement already satisfied: PyYAML in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from cliff->optuna) (3.5.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from cliff->optuna) (4.1.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from stevedore>=2.0.1->cliff->optuna) (5.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/troflianina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/troflianina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/troflianina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/troflianina/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "stopwords = nltk_stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка датасета со всеми сэмплами\n",
    "tweets = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление ненужной колонки\n",
    "tweets = tweets.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество пропущенных значений\n",
    "tweets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка на дисбаланс классов\n",
    "tweets[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выборка с 6000 признаками для создания эмбеддингов с помощью BERT \n",
    "tweets_bert = resample(\n",
    "    tweets, n_samples=6000, random_state=SEED, stratify=tweets['toxic']\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** я загрузила исходный датасет `tweets` со всеми твитами для работы с `TF-IDF` и `Word2vec` и отдельно создала выборку из 6000 твитов для дальнейшего извлечения эмбеддингов для предобученной `BERT` модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация и удаление стоп-слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с TF-IDF и Word2vec необходимо подготовить признаки, а именно лемматизировать текст, удалить из него стоп-слова и привести все символы к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z']\", ' ', text)\n",
    "    return ' '.join(text.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 10000 твитов\n",
      "Обработано 20000 твитов\n",
      "Обработано 30000 твитов\n",
      "Обработано 40000 твитов\n",
      "Обработано 50000 твитов\n",
      "Обработано 60000 твитов\n",
      "Обработано 70000 твитов\n",
      "Обработано 80000 твитов\n",
      "Обработано 90000 твитов\n",
      "Обработано 100000 твитов\n",
      "Обработано 110000 твитов\n",
      "Обработано 120000 твитов\n",
      "Обработано 130000 твитов\n",
      "Обработано 140000 твитов\n",
      "Обработано 150000 твитов\n",
      "CPU times: user 2min 51s, sys: 4.27 s, total: 2min 55s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lemmatized_text = []\n",
    "count = 0\n",
    "\n",
    "for doc in lemmatizer.pipe(tweets['text'].apply(clear_text), n_process=-1):\n",
    "    word_list = [\n",
    "        word.lemma_ for word in doc\n",
    "        if word.lemma_ not in stopwords\n",
    "    ]\n",
    "    lemmatized_text.append(' '.join(word_list))\n",
    "    count += 1\n",
    "    if count % 10000 == 0:\n",
    "        print('Обработано', count, 'твитов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text_lemma'] = lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour I seemingly stic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man I really try edit war guy constantly r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>I make real suggestion improvement I wonder se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          text_lemma  \n",
       "0  explanation edit make username hardcore metall...  \n",
       "1  d'aww match background colour I seemingly stic...  \n",
       "2  hey man I really try edit war guy constantly r...  \n",
       "3  I make real suggestion improvement I wonder se...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение данных на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tweets['toxic']\n",
    "target_bert = tweets_bert['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "features_tfidf_train, features_tfidf_test, target_tfidf_train, target_tfidf_test = train_test_split(\n",
    "    tweets['text_lemma'], target, test_size=0.25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "features_wordvec_train, features_wordvec_test, target_wordvec_train, target_wordvec_test = train_test_split(\n",
    "    tweets['text_lemma'], target, test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert\n",
    "features_bert_train, features_bert_test, target_bert_train, target_bert_test = train_test_split(\n",
    "    tweets_bert['text'], target_bert, test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469,)\n",
      "(119469,)\n",
      "(39823,)\n",
      "(39823,)\n"
     ]
    }
   ],
   "source": [
    "print(features_tfidf_train.shape)\n",
    "print(target_tfidf_train.shape)\n",
    "print(features_tfidf_test.shape)\n",
    "print(target_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469,)\n",
      "(119469,)\n",
      "(39823,)\n",
      "(39823,)\n"
     ]
    }
   ],
   "source": [
    "print(features_wordvec_train.shape)\n",
    "print(target_wordvec_train.shape)\n",
    "print(features_wordvec_test.shape)\n",
    "print(target_wordvec_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500,)\n",
      "(4500,)\n",
      "(1500,)\n",
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "print(features_bert_train.shape)\n",
    "print(target_bert_train.shape)\n",
    "print(features_bert_test.shape)\n",
    "print(target_bert_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5439     maybe sentence could something like form w tor...\n",
       "55140    I guess jfd try discourage get touch I via e m...\n",
       "99008    sorry seem little harsh thing go little tit sp...\n",
       "30599    favor hey still talk outstanding oppose wikipe...\n",
       "3872     please stop add nonsense wikipedia consider va...\n",
       "Name: text_lemma, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_wordvec_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подход TF-IDF учитывает встречаемость слова не только в отдельном тексте (или твите), но и во всем корпусе текстов. \n",
    "TF отвечает за количество упоминаний слова в отдельном тексте, а IDF отражает частоту его употребления во всём корпусе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF = t/n, где t - количество употребления слова, а n — общее число слов в тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF = log(D/d), где D - общее число текстов в корпусе, d - количество текстов, в которых это слово встречается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TFIDF = TF * IDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(features_tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119469, 127526)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразование тестовой выборки\n",
    "tfidf_test = tfidf_vectorizer.transform(features_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39823, 127526)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings - способ представления слов в виде векторов, при котором сохраняется семантическая связь между словами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизация текста\n",
    "tokenized_tweet = features_wordvec_train.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5439      [maybe, sentence, could, something, like, form...\n",
       "55140     [I, guess, jfd, try, discourage, get, touch, I...\n",
       "99008     [sorry, seem, little, harsh, thing, go, little...\n",
       "30599     [favor, hey, still, talk, outstanding, oppose,...\n",
       "3872      [please, stop, add, nonsense, wikipedia, consi...\n",
       "                                ...                        \n",
       "90930     [I, hope, right, way, reply, good, question, c...\n",
       "157798    [push, advise, dig, source, c, e, e, fact, che...\n",
       "80775     [since, ask, cite, bresloff, 's, involvement, ...\n",
       "89265     [I, continue, edit, page, lock, formal, vote, ...\n",
       "89325     [go, go, around, circle, wrong, I, already, ta...\n",
       "Name: text_lemma, Length: 119469, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 14:36:06,742 : INFO : collecting all words and their counts\n",
      "2022-11-15 14:36:06,743 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-11-15 14:36:06,796 : INFO : PROGRESS: at sentence #10000, processed 366311 words, keeping 28304 word types\n",
      "2022-11-15 14:36:06,848 : INFO : PROGRESS: at sentence #20000, processed 731481 words, keeping 43376 word types\n",
      "2022-11-15 14:36:06,900 : INFO : PROGRESS: at sentence #30000, processed 1093351 words, keeping 55587 word types\n",
      "2022-11-15 14:36:06,951 : INFO : PROGRESS: at sentence #40000, processed 1460817 words, keeping 66315 word types\n",
      "2022-11-15 14:36:07,004 : INFO : PROGRESS: at sentence #50000, processed 1830579 words, keeping 76174 word types\n",
      "2022-11-15 14:36:07,060 : INFO : PROGRESS: at sentence #60000, processed 2207618 words, keeping 85344 word types\n",
      "2022-11-15 14:36:07,114 : INFO : PROGRESS: at sentence #70000, processed 2572722 words, keeping 93229 word types\n",
      "2022-11-15 14:36:07,167 : INFO : PROGRESS: at sentence #80000, processed 2938729 words, keeping 100898 word types\n",
      "2022-11-15 14:36:07,222 : INFO : PROGRESS: at sentence #90000, processed 3314449 words, keeping 108309 word types\n",
      "2022-11-15 14:36:07,275 : INFO : PROGRESS: at sentence #100000, processed 3683027 words, keeping 115215 word types\n",
      "2022-11-15 14:36:07,331 : INFO : PROGRESS: at sentence #110000, processed 4062863 words, keeping 122446 word types\n",
      "2022-11-15 14:36:07,382 : INFO : collected 128508 word types from a corpus of 4407961 raw words and 119469 sentences\n",
      "2022-11-15 14:36:07,383 : INFO : Creating a fresh vocabulary\n",
      "2022-11-15 14:36:07,570 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 61436 unique words (47.81% of original 128508, drops 67072)', 'datetime': '2022-11-15T14:36:07.570175', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-15 14:36:07,570 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 4340889 word corpus (98.48% of original 4407961, drops 67072)', 'datetime': '2022-11-15T14:36:07.570709', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-15 14:36:07,843 : INFO : deleting the raw counts dictionary of 128508 items\n",
      "2022-11-15 14:36:07,847 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2022-11-15 14:36:07,849 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3931225.8376355264 word corpus (90.6%% of prior 4340889)', 'datetime': '2022-11-15T14:36:07.849114', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-15 14:36:08,239 : INFO : estimated required memory for 61436 words and 300 dimensions: 178164400 bytes\n",
      "2022-11-15 14:36:08,239 : INFO : resetting layer weights\n",
      "2022-11-15 14:36:08,314 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-15T14:36:08.314627', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
      "2022-11-15 14:36:08,315 : INFO : Word2Vec lifecycle event {'msg': 'training model with 32 workers on 61436 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=10 window=4 shrink_windows=True', 'datetime': '2022-11-15T14:36:08.315230', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2022-11-15 14:36:09,434 : INFO : EPOCH 0 - PROGRESS: at 5.29% examples, 185481 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:10,438 : INFO : EPOCH 0 - PROGRESS: at 14.61% examples, 270025 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:11,489 : INFO : EPOCH 0 - PROGRESS: at 22.96% examples, 284103 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:12,532 : INFO : EPOCH 0 - PROGRESS: at 31.44% examples, 291588 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:36:13,571 : INFO : EPOCH 0 - PROGRESS: at 40.43% examples, 301445 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:14,579 : INFO : EPOCH 0 - PROGRESS: at 49.53% examples, 310868 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:36:15,601 : INFO : EPOCH 0 - PROGRESS: at 59.08% examples, 318450 words/s, in_qsize 64, out_qsize 1\n",
      "2022-11-15 14:36:16,654 : INFO : EPOCH 0 - PROGRESS: at 67.03% examples, 315368 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:17,676 : INFO : EPOCH 0 - PROGRESS: at 75.47% examples, 316958 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:36:18,773 : INFO : EPOCH 0 - PROGRESS: at 85.50% examples, 322880 words/s, in_qsize 63, out_qsize 2\n",
      "2022-11-15 14:36:19,740 : INFO : EPOCH 0 - PROGRESS: at 94.40% examples, 325603 words/s, in_qsize 25, out_qsize 1\n",
      "2022-11-15 14:36:19,995 : INFO : EPOCH 0: training on 4407961 raw words (3931144 effective words) took 11.7s, 337213 effective words/s\n",
      "2022-11-15 14:36:21,009 : INFO : EPOCH 1 - PROGRESS: at 5.25% examples, 202582 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:22,028 : INFO : EPOCH 1 - PROGRESS: at 13.90% examples, 267584 words/s, in_qsize 64, out_qsize 1\n",
      "2022-11-15 14:36:23,051 : INFO : EPOCH 1 - PROGRESS: at 22.51% examples, 289381 words/s, in_qsize 63, out_qsize 2\n",
      "2022-11-15 14:36:24,046 : INFO : EPOCH 1 - PROGRESS: at 31.86% examples, 307215 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:25,094 : INFO : EPOCH 1 - PROGRESS: at 40.49% examples, 310136 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:36:26,111 : INFO : EPOCH 1 - PROGRESS: at 49.50% examples, 317978 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:27,121 : INFO : EPOCH 1 - PROGRESS: at 58.93% examples, 323961 words/s, in_qsize 64, out_qsize 2\n",
      "2022-11-15 14:36:28,150 : INFO : EPOCH 1 - PROGRESS: at 68.14% examples, 327579 words/s, in_qsize 64, out_qsize 3\n",
      "2022-11-15 14:36:29,264 : INFO : EPOCH 1 - PROGRESS: at 78.39% examples, 332057 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:36:30,295 : INFO : EPOCH 1 - PROGRESS: at 87.27% examples, 333343 words/s, in_qsize 57, out_qsize 0\n",
      "2022-11-15 14:36:31,298 : INFO : EPOCH 1 - PROGRESS: at 99.58% examples, 346612 words/s, in_qsize 2, out_qsize 1\n",
      "2022-11-15 14:36:31,310 : INFO : EPOCH 1: training on 4407961 raw words (3931427 effective words) took 11.3s, 347815 effective words/s\n",
      "2022-11-15 14:36:32,368 : INFO : EPOCH 2 - PROGRESS: at 4.40% examples, 160514 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:33,387 : INFO : EPOCH 2 - PROGRESS: at 13.87% examples, 261379 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:34,414 : INFO : EPOCH 2 - PROGRESS: at 20.49% examples, 258074 words/s, in_qsize 63, out_qsize 3\n",
      "2022-11-15 14:36:35,475 : INFO : EPOCH 2 - PROGRESS: at 30.09% examples, 285489 words/s, in_qsize 64, out_qsize 2\n",
      "2022-11-15 14:36:36,424 : INFO : EPOCH 2 - PROGRESS: at 38.63% examples, 295274 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:36:37,455 : INFO : EPOCH 2 - PROGRESS: at 47.18% examples, 300405 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:36:38,473 : INFO : EPOCH 2 - PROGRESS: at 55.41% examples, 303481 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:36:39,584 : INFO : EPOCH 2 - PROGRESS: at 65.39% examples, 309862 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:40,640 : INFO : EPOCH 2 - PROGRESS: at 74.49% examples, 313779 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:41,672 : INFO : EPOCH 2 - PROGRESS: at 82.39% examples, 312375 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:36:42,764 : INFO : EPOCH 2 - PROGRESS: at 91.66% examples, 315128 words/s, in_qsize 37, out_qsize 0\n",
      "2022-11-15 14:36:43,367 : INFO : EPOCH 2: training on 4407961 raw words (3930541 effective words) took 12.0s, 326307 effective words/s\n",
      "2022-11-15 14:36:44,384 : INFO : EPOCH 3 - PROGRESS: at 2.91% examples, 114006 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:45,387 : INFO : EPOCH 3 - PROGRESS: at 12.52% examples, 242568 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:46,487 : INFO : EPOCH 3 - PROGRESS: at 21.46% examples, 267991 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:36:47,500 : INFO : EPOCH 3 - PROGRESS: at 31.22% examples, 294551 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:48,505 : INFO : EPOCH 3 - PROGRESS: at 39.22% examples, 299189 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:49,560 : INFO : EPOCH 3 - PROGRESS: at 48.05% examples, 305314 words/s, in_qsize 63, out_qsize 1\n",
      "2022-11-15 14:36:50,555 : INFO : EPOCH 3 - PROGRESS: at 55.68% examples, 303808 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:51,580 : INFO : EPOCH 3 - PROGRESS: at 64.87% examples, 310137 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:52,632 : INFO : EPOCH 3 - PROGRESS: at 73.65% examples, 312217 words/s, in_qsize 64, out_qsize 3\n",
      "2022-11-15 14:36:53,642 : INFO : EPOCH 3 - PROGRESS: at 82.90% examples, 316836 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:54,694 : INFO : EPOCH 3 - PROGRESS: at 91.25% examples, 317233 words/s, in_qsize 39, out_qsize 0\n",
      "2022-11-15 14:36:55,378 : INFO : EPOCH 3: training on 4407961 raw words (3932167 effective words) took 12.0s, 327677 effective words/s\n",
      "2022-11-15 14:36:56,399 : INFO : EPOCH 4 - PROGRESS: at 2.61% examples, 104919 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:36:57,440 : INFO : EPOCH 4 - PROGRESS: at 12.71% examples, 241882 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:58,452 : INFO : EPOCH 4 - PROGRESS: at 20.69% examples, 263220 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:36:59,487 : INFO : EPOCH 4 - PROGRESS: at 28.73% examples, 272543 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:00,493 : INFO : EPOCH 4 - PROGRESS: at 36.42% examples, 277847 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:01,544 : INFO : EPOCH 4 - PROGRESS: at 45.60% examples, 289408 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:02,560 : INFO : EPOCH 4 - PROGRESS: at 53.61% examples, 292889 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:03,563 : INFO : EPOCH 4 - PROGRESS: at 61.55% examples, 294907 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:04,591 : INFO : EPOCH 4 - PROGRESS: at 70.01% examples, 298600 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:05,673 : INFO : EPOCH 4 - PROGRESS: at 78.47% examples, 298908 words/s, in_qsize 61, out_qsize 8\n",
      "2022-11-15 14:37:06,696 : INFO : EPOCH 4 - PROGRESS: at 87.29% examples, 303328 words/s, in_qsize 57, out_qsize 0\n",
      "2022-11-15 14:37:07,669 : INFO : EPOCH 4: training on 4407961 raw words (3930823 effective words) took 12.3s, 320142 effective words/s\n",
      "2022-11-15 14:37:07,670 : INFO : Word2Vec lifecycle event {'msg': 'training on 22039805 raw words (19656102 effective words) took 59.4s, 331165 effective words/s', 'datetime': '2022-11-15T14:37:07.670057', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2022-11-15 14:37:07,670 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=61436, vector_size=300, alpha=0.025>', 'datetime': '2022-11-15T14:37:07.670633', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'created'}\n",
      "2022-11-15 14:37:07,675 : INFO : collecting all words and their counts\n",
      "2022-11-15 14:37:07,676 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-11-15 14:37:07,725 : INFO : PROGRESS: at sentence #10000, processed 366311 words, keeping 28304 word types\n",
      "2022-11-15 14:37:07,777 : INFO : PROGRESS: at sentence #20000, processed 731481 words, keeping 43376 word types\n",
      "2022-11-15 14:37:07,828 : INFO : PROGRESS: at sentence #30000, processed 1093351 words, keeping 55587 word types\n",
      "2022-11-15 14:37:07,880 : INFO : PROGRESS: at sentence #40000, processed 1460817 words, keeping 66315 word types\n",
      "2022-11-15 14:37:07,932 : INFO : PROGRESS: at sentence #50000, processed 1830579 words, keeping 76174 word types\n",
      "2022-11-15 14:37:07,985 : INFO : PROGRESS: at sentence #60000, processed 2207618 words, keeping 85344 word types\n",
      "2022-11-15 14:37:08,038 : INFO : PROGRESS: at sentence #70000, processed 2572722 words, keeping 93229 word types\n",
      "2022-11-15 14:37:08,090 : INFO : PROGRESS: at sentence #80000, processed 2938729 words, keeping 100898 word types\n",
      "2022-11-15 14:37:08,143 : INFO : PROGRESS: at sentence #90000, processed 3314449 words, keeping 108309 word types\n",
      "2022-11-15 14:37:08,211 : INFO : PROGRESS: at sentence #100000, processed 3683027 words, keeping 115215 word types\n",
      "2022-11-15 14:37:08,265 : INFO : PROGRESS: at sentence #110000, processed 4062863 words, keeping 122446 word types\n",
      "2022-11-15 14:37:08,314 : INFO : collected 128508 word types from a corpus of 4407961 raw words and 119469 sentences\n",
      "2022-11-15 14:37:08,314 : INFO : Creating a fresh vocabulary\n",
      "2022-11-15 14:37:08,539 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 61436 unique words (47.81% of original 128508, drops 67072)', 'datetime': '2022-11-15T14:37:08.539111', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-15 14:37:08,539 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 4340889 word corpus (98.48% of original 4407961, drops 67072)', 'datetime': '2022-11-15T14:37:08.539798', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-15 14:37:08,834 : INFO : deleting the raw counts dictionary of 128508 items\n",
      "2022-11-15 14:37:08,836 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2022-11-15 14:37:08,837 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3931225.8376355264 word corpus (90.6%% of prior 4340889)', 'datetime': '2022-11-15T14:37:08.837118', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-15 14:37:08,851 : WARNING : sorting after vectors have been allocated is expensive & error-prone\n",
      "2022-11-15 14:37:09,320 : INFO : estimated required memory for 61436 words and 300 dimensions: 178164400 bytes\n",
      "2022-11-15 14:37:09,321 : INFO : resetting layer weights\n",
      "2022-11-15 14:37:09,326 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-15T14:37:09.326431', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
      "2022-11-15 14:37:09,327 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2022-11-15 14:37:09,327 : INFO : Word2Vec lifecycle event {'msg': 'training model with 32 workers on 61436 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=10 window=4 shrink_windows=True', 'datetime': '2022-11-15T14:37:09.327651', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2022-11-15 14:37:10,389 : INFO : EPOCH 0 - PROGRESS: at 2.72% examples, 101604 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:11,417 : INFO : EPOCH 0 - PROGRESS: at 10.94% examples, 204945 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:12,487 : INFO : EPOCH 0 - PROGRESS: at 20.37% examples, 250620 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:37:13,489 : INFO : EPOCH 0 - PROGRESS: at 29.61% examples, 277814 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:14,494 : INFO : EPOCH 0 - PROGRESS: at 38.25% examples, 288929 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:15,515 : INFO : EPOCH 0 - PROGRESS: at 45.34% examples, 287059 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:16,635 : INFO : EPOCH 0 - PROGRESS: at 53.85% examples, 289185 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:17,642 : INFO : EPOCH 0 - PROGRESS: at 62.83% examples, 296737 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:18,684 : INFO : EPOCH 0 - PROGRESS: at 70.93% examples, 297883 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:19,723 : INFO : EPOCH 0 - PROGRESS: at 79.78% examples, 301249 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:20,768 : INFO : EPOCH 0 - PROGRESS: at 87.93% examples, 302407 words/s, in_qsize 53, out_qsize 1\n",
      "2022-11-15 14:37:21,794 : INFO : EPOCH 0 - PROGRESS: at 96.92% examples, 305978 words/s, in_qsize 14, out_qsize 1\n",
      "2022-11-15 14:37:21,956 : INFO : EPOCH 0: training on 4407961 raw words (3931608 effective words) took 12.6s, 311650 effective words/s\n",
      "2022-11-15 14:37:22,977 : INFO : EPOCH 1 - PROGRESS: at 4.13% examples, 157698 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:24,012 : INFO : EPOCH 1 - PROGRESS: at 13.24% examples, 251523 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:25,045 : INFO : EPOCH 1 - PROGRESS: at 22.29% examples, 282383 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:26,049 : INFO : EPOCH 1 - PROGRESS: at 30.75% examples, 293249 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:27,124 : INFO : EPOCH 1 - PROGRESS: at 38.77% examples, 294119 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:28,138 : INFO : EPOCH 1 - PROGRESS: at 47.09% examples, 298858 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:29,179 : INFO : EPOCH 1 - PROGRESS: at 56.17% examples, 304849 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:30,255 : INFO : EPOCH 1 - PROGRESS: at 64.87% examples, 306941 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:31,304 : INFO : EPOCH 1 - PROGRESS: at 73.34% examples, 309014 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:32,296 : INFO : EPOCH 1 - PROGRESS: at 81.37% examples, 308878 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:37:33,308 : INFO : EPOCH 1 - PROGRESS: at 90.21% examples, 312631 words/s, in_qsize 44, out_qsize 0\n",
      "2022-11-15 14:37:34,041 : INFO : EPOCH 1: training on 4407961 raw words (3931589 effective words) took 12.1s, 325702 effective words/s\n",
      "2022-11-15 14:37:35,058 : INFO : EPOCH 2 - PROGRESS: at 4.51% examples, 175864 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:36,119 : INFO : EPOCH 2 - PROGRESS: at 13.44% examples, 252803 words/s, in_qsize 60, out_qsize 3\n",
      "2022-11-15 14:37:37,126 : INFO : EPOCH 2 - PROGRESS: at 23.68% examples, 299713 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:38,183 : INFO : EPOCH 2 - PROGRESS: at 32.61% examples, 306741 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:39,196 : INFO : EPOCH 2 - PROGRESS: at 41.31% examples, 313647 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:40,223 : INFO : EPOCH 2 - PROGRESS: at 50.49% examples, 320280 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:41,241 : INFO : EPOCH 2 - PROGRESS: at 60.19% examples, 327925 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:42,261 : INFO : EPOCH 2 - PROGRESS: at 68.53% examples, 327188 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:43,284 : INFO : EPOCH 2 - PROGRESS: at 76.17% examples, 323485 words/s, in_qsize 60, out_qsize 3\n",
      "2022-11-15 14:37:44,288 : INFO : EPOCH 2 - PROGRESS: at 83.97% examples, 322050 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:45,299 : INFO : EPOCH 2 - PROGRESS: at 91.94% examples, 321535 words/s, in_qsize 35, out_qsize 1\n",
      "2022-11-15 14:37:45,862 : INFO : EPOCH 2: training on 4407961 raw words (3931592 effective words) took 11.8s, 332933 effective words/s\n",
      "2022-11-15 14:37:46,895 : INFO : EPOCH 3 - PROGRESS: at 3.44% examples, 130163 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:47,924 : INFO : EPOCH 3 - PROGRESS: at 13.00% examples, 246302 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:48,977 : INFO : EPOCH 3 - PROGRESS: at 21.80% examples, 274124 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:50,053 : INFO : EPOCH 3 - PROGRESS: at 31.39% examples, 292644 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:37:51,071 : INFO : EPOCH 3 - PROGRESS: at 40.25% examples, 301936 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:52,086 : INFO : EPOCH 3 - PROGRESS: at 48.74% examples, 306687 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:53,088 : INFO : EPOCH 3 - PROGRESS: at 58.20% examples, 315691 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:54,096 : INFO : EPOCH 3 - PROGRESS: at 65.51% examples, 312574 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:37:55,172 : INFO : EPOCH 3 - PROGRESS: at 73.36% examples, 309728 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:56,249 : INFO : EPOCH 3 - PROGRESS: at 82.83% examples, 313395 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:37:57,312 : INFO : EPOCH 3 - PROGRESS: at 91.88% examples, 316125 words/s, in_qsize 34, out_qsize 2\n",
      "2022-11-15 14:37:57,756 : INFO : EPOCH 3: training on 4407961 raw words (3931186 effective words) took 11.9s, 330862 effective words/s\n",
      "2022-11-15 14:37:58,786 : INFO : EPOCH 4 - PROGRESS: at 4.58% examples, 173481 words/s, in_qsize 62, out_qsize 3\n",
      "2022-11-15 14:37:59,808 : INFO : EPOCH 4 - PROGRESS: at 14.10% examples, 269333 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:00,863 : INFO : EPOCH 4 - PROGRESS: at 23.16% examples, 292079 words/s, in_qsize 60, out_qsize 5\n",
      "2022-11-15 14:38:01,910 : INFO : EPOCH 4 - PROGRESS: at 32.33% examples, 303798 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:02,982 : INFO : EPOCH 4 - PROGRESS: at 40.56% examples, 304172 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:03,984 : INFO : EPOCH 4 - PROGRESS: at 48.44% examples, 305090 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:38:05,012 : INFO : EPOCH 4 - PROGRESS: at 57.75% examples, 311940 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:38:06,044 : INFO : EPOCH 4 - PROGRESS: at 67.02% examples, 316961 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:07,096 : INFO : EPOCH 4 - PROGRESS: at 76.16% examples, 320120 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:08,099 : INFO : EPOCH 4 - PROGRESS: at 85.27% examples, 324190 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:09,150 : INFO : EPOCH 4 - PROGRESS: at 93.82% examples, 324671 words/s, in_qsize 27, out_qsize 1\n",
      "2022-11-15 14:38:09,402 : INFO : EPOCH 4: training on 4407961 raw words (3931213 effective words) took 11.6s, 337917 effective words/s\n",
      "2022-11-15 14:38:10,425 : INFO : EPOCH 5 - PROGRESS: at 5.47% examples, 210286 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:38:11,455 : INFO : EPOCH 5 - PROGRESS: at 13.91% examples, 264918 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:12,471 : INFO : EPOCH 5 - PROGRESS: at 22.63% examples, 287014 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:38:13,511 : INFO : EPOCH 5 - PROGRESS: at 31.39% examples, 298596 words/s, in_qsize 57, out_qsize 6\n",
      "2022-11-15 14:38:14,560 : INFO : EPOCH 5 - PROGRESS: at 40.19% examples, 304896 words/s, in_qsize 64, out_qsize 1\n",
      "2022-11-15 14:38:15,657 : INFO : EPOCH 5 - PROGRESS: at 48.89% examples, 306590 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:38:16,673 : INFO : EPOCH 5 - PROGRESS: at 58.37% examples, 315029 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:38:17,735 : INFO : EPOCH 5 - PROGRESS: at 67.95% examples, 319561 words/s, in_qsize 64, out_qsize 3\n",
      "2022-11-15 14:38:18,757 : INFO : EPOCH 5 - PROGRESS: at 77.55% examples, 325260 words/s, in_qsize 64, out_qsize 2\n",
      "2022-11-15 14:38:19,782 : INFO : EPOCH 5 - PROGRESS: at 85.26% examples, 323084 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:20,921 : INFO : EPOCH 5 - PROGRESS: at 93.52% examples, 319662 words/s, in_qsize 29, out_qsize 2\n",
      "2022-11-15 14:38:21,229 : INFO : EPOCH 5: training on 4407961 raw words (3931837 effective words) took 11.8s, 332802 effective words/s\n",
      "2022-11-15 14:38:22,245 : INFO : EPOCH 6 - PROGRESS: at 3.00% examples, 114573 words/s, in_qsize 63, out_qsize 8\n",
      "2022-11-15 14:38:23,304 : INFO : EPOCH 6 - PROGRESS: at 12.78% examples, 240494 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:24,310 : INFO : EPOCH 6 - PROGRESS: at 20.69% examples, 262793 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:25,432 : INFO : EPOCH 6 - PROGRESS: at 29.15% examples, 273984 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:26,407 : INFO : EPOCH 6 - PROGRESS: at 36.63% examples, 276198 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:27,436 : INFO : EPOCH 6 - PROGRESS: at 44.00% examples, 277509 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:28,448 : INFO : EPOCH 6 - PROGRESS: at 51.84% examples, 281503 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:29,490 : INFO : EPOCH 6 - PROGRESS: at 59.49% examples, 282601 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:38:30,508 : INFO : EPOCH 6 - PROGRESS: at 68.19% examples, 287870 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:31,523 : INFO : EPOCH 6 - PROGRESS: at 75.93% examples, 289590 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:32,564 : INFO : EPOCH 6 - PROGRESS: at 84.02% examples, 291096 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:33,564 : INFO : EPOCH 6 - PROGRESS: at 90.62% examples, 289132 words/s, in_qsize 42, out_qsize 0\n",
      "2022-11-15 14:38:34,246 : INFO : EPOCH 6: training on 4407961 raw words (3931842 effective words) took 13.0s, 302348 effective words/s\n",
      "2022-11-15 14:38:35,264 : INFO : EPOCH 7 - PROGRESS: at 2.93% examples, 114337 words/s, in_qsize 58, out_qsize 5\n",
      "2022-11-15 14:38:36,292 : INFO : EPOCH 7 - PROGRESS: at 12.84% examples, 244188 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:37,302 : INFO : EPOCH 7 - PROGRESS: at 23.52% examples, 299753 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:38,302 : INFO : EPOCH 7 - PROGRESS: at 32.59% examples, 313342 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:39,322 : INFO : EPOCH 7 - PROGRESS: at 41.31% examples, 318585 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:40,364 : INFO : EPOCH 7 - PROGRESS: at 50.01% examples, 320715 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:41,384 : INFO : EPOCH 7 - PROGRESS: at 58.17% examples, 319581 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:42,406 : INFO : EPOCH 7 - PROGRESS: at 66.56% examples, 319708 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:38:43,430 : INFO : EPOCH 7 - PROGRESS: at 76.19% examples, 325579 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:38:44,499 : INFO : EPOCH 7 - PROGRESS: at 85.08% examples, 326103 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:38:45,501 : INFO : EPOCH 7 - PROGRESS: at 94.21% examples, 329441 words/s, in_qsize 26, out_qsize 1\n",
      "2022-11-15 14:38:45,928 : INFO : EPOCH 7: training on 4407961 raw words (3930797 effective words) took 11.7s, 336818 effective words/s\n",
      "2022-11-15 14:38:46,963 : INFO : EPOCH 8 - PROGRESS: at 3.41% examples, 130281 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:47,969 : INFO : EPOCH 8 - PROGRESS: at 12.71% examples, 244415 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:38:49,026 : INFO : EPOCH 8 - PROGRESS: at 22.57% examples, 284345 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:38:50,041 : INFO : EPOCH 8 - PROGRESS: at 31.42% examples, 298262 words/s, in_qsize 64, out_qsize 6\n",
      "2022-11-15 14:38:51,041 : INFO : EPOCH 8 - PROGRESS: at 40.20% examples, 307555 words/s, in_qsize 63, out_qsize 6\n",
      "2022-11-15 14:38:52,059 : INFO : EPOCH 8 - PROGRESS: at 49.43% examples, 315737 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:53,059 : INFO : EPOCH 8 - PROGRESS: at 58.88% examples, 323669 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:54,105 : INFO : EPOCH 8 - PROGRESS: at 68.52% examples, 328889 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:38:55,154 : INFO : EPOCH 8 - PROGRESS: at 77.74% examples, 330729 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:38:56,173 : INFO : EPOCH 8 - PROGRESS: at 85.94% examples, 330158 words/s, in_qsize 63, out_qsize 2\n",
      "2022-11-15 14:38:57,183 : INFO : EPOCH 8 - PROGRESS: at 96.66% examples, 338141 words/s, in_qsize 15, out_qsize 1\n",
      "2022-11-15 14:38:57,328 : INFO : EPOCH 8: training on 4407961 raw words (3931418 effective words) took 11.4s, 345224 effective words/s\n",
      "2022-11-15 14:38:58,385 : INFO : EPOCH 9 - PROGRESS: at 4.39% examples, 161648 words/s, in_qsize 64, out_qsize 4\n",
      "2022-11-15 14:38:59,385 : INFO : EPOCH 9 - PROGRESS: at 14.10% examples, 268884 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:39:00,411 : INFO : EPOCH 9 - PROGRESS: at 23.63% examples, 300182 words/s, in_qsize 63, out_qsize 3\n",
      "2022-11-15 14:39:01,428 : INFO : EPOCH 9 - PROGRESS: at 32.82% examples, 312250 words/s, in_qsize 64, out_qsize 1\n",
      "2022-11-15 14:39:02,436 : INFO : EPOCH 9 - PROGRESS: at 41.80% examples, 320079 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:03,505 : INFO : EPOCH 9 - PROGRESS: at 50.64% examples, 322087 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:04,570 : INFO : EPOCH 9 - PROGRESS: at 60.36% examples, 327305 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:05,581 : INFO : EPOCH 9 - PROGRESS: at 68.56% examples, 325848 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:06,591 : INFO : EPOCH 9 - PROGRESS: at 78.48% examples, 332309 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:07,600 : INFO : EPOCH 9 - PROGRESS: at 86.84% examples, 332560 words/s, in_qsize 59, out_qsize 0\n",
      "2022-11-15 14:39:08,604 : INFO : EPOCH 9 - PROGRESS: at 97.71% examples, 341213 words/s, in_qsize 10, out_qsize 1\n",
      "2022-11-15 14:39:08,687 : INFO : EPOCH 9: training on 4407961 raw words (3931492 effective words) took 11.3s, 346490 effective words/s\n",
      "2022-11-15 14:39:09,718 : INFO : EPOCH 10 - PROGRESS: at 4.79% examples, 182253 words/s, in_qsize 60, out_qsize 3\n",
      "2022-11-15 14:39:10,729 : INFO : EPOCH 10 - PROGRESS: at 13.89% examples, 266104 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:39:11,754 : INFO : EPOCH 10 - PROGRESS: at 23.49% examples, 298807 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:39:12,802 : INFO : EPOCH 10 - PROGRESS: at 32.83% examples, 311037 words/s, in_qsize 60, out_qsize 3\n",
      "2022-11-15 14:39:13,804 : INFO : EPOCH 10 - PROGRESS: at 42.13% examples, 323044 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:14,814 : INFO : EPOCH 10 - PROGRESS: at 49.95% examples, 320257 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:15,822 : INFO : EPOCH 10 - PROGRESS: at 58.54% examples, 322220 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:16,852 : INFO : EPOCH 10 - PROGRESS: at 68.28% examples, 328330 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:39:17,878 : INFO : EPOCH 10 - PROGRESS: at 78.19% examples, 333953 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:18,924 : INFO : EPOCH 10 - PROGRESS: at 86.85% examples, 333692 words/s, in_qsize 59, out_qsize 0\n",
      "2022-11-15 14:39:19,933 : INFO : EPOCH 10 - PROGRESS: at 95.91% examples, 336079 words/s, in_qsize 18, out_qsize 1\n",
      "2022-11-15 14:39:20,100 : INFO : EPOCH 10: training on 4407961 raw words (3931813 effective words) took 11.4s, 344874 effective words/s\n",
      "2022-11-15 14:39:21,113 : INFO : EPOCH 11 - PROGRESS: at 4.56% examples, 176255 words/s, in_qsize 63, out_qsize 2\n",
      "2022-11-15 14:39:22,125 : INFO : EPOCH 11 - PROGRESS: at 14.12% examples, 272615 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:39:23,125 : INFO : EPOCH 11 - PROGRESS: at 22.31% examples, 288146 words/s, in_qsize 62, out_qsize 0\n",
      "2022-11-15 14:39:24,138 : INFO : EPOCH 11 - PROGRESS: at 31.23% examples, 301485 words/s, in_qsize 62, out_qsize 3\n",
      "2022-11-15 14:39:25,164 : INFO : EPOCH 11 - PROGRESS: at 41.00% examples, 315665 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:26,201 : INFO : EPOCH 11 - PROGRESS: at 50.19% examples, 323044 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:27,208 : INFO : EPOCH 11 - PROGRESS: at 59.69% examples, 329631 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:28,238 : INFO : EPOCH 11 - PROGRESS: at 67.91% examples, 327118 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:39:29,266 : INFO : EPOCH 11 - PROGRESS: at 77.30% examples, 330953 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:30,275 : INFO : EPOCH 11 - PROGRESS: at 86.38% examples, 333888 words/s, in_qsize 61, out_qsize 0\n",
      "2022-11-15 14:39:31,290 : INFO : EPOCH 11 - PROGRESS: at 96.18% examples, 338484 words/s, in_qsize 17, out_qsize 1\n",
      "2022-11-15 14:39:31,467 : INFO : EPOCH 11: training on 4407961 raw words (3931154 effective words) took 11.4s, 346165 effective words/s\n",
      "2022-11-15 14:39:32,521 : INFO : EPOCH 12 - PROGRESS: at 4.22% examples, 161445 words/s, in_qsize 53, out_qsize 10\n",
      "2022-11-15 14:39:33,540 : INFO : EPOCH 12 - PROGRESS: at 14.80% examples, 281644 words/s, in_qsize 61, out_qsize 6\n",
      "2022-11-15 14:39:34,536 : INFO : EPOCH 12 - PROGRESS: at 23.71% examples, 301578 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:35,565 : INFO : EPOCH 12 - PROGRESS: at 34.15% examples, 325376 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:39:36,734 : INFO : EPOCH 12 - PROGRESS: at 44.08% examples, 327602 words/s, in_qsize 63, out_qsize 1\n",
      "2022-11-15 14:39:37,754 : INFO : EPOCH 12 - PROGRESS: at 53.85% examples, 336050 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:39:38,758 : INFO : EPOCH 12 - PROGRESS: at 61.99% examples, 333552 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:39,758 : INFO : EPOCH 12 - PROGRESS: at 70.97% examples, 336088 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:40,809 : INFO : EPOCH 12 - PROGRESS: at 79.98% examples, 336085 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:41,848 : INFO : EPOCH 12 - PROGRESS: at 88.89% examples, 336649 words/s, in_qsize 50, out_qsize 0\n",
      "2022-11-15 14:39:42,721 : INFO : EPOCH 12: training on 4407961 raw words (3930742 effective words) took 11.2s, 349663 effective words/s\n",
      "2022-11-15 14:39:43,743 : INFO : EPOCH 13 - PROGRESS: at 4.72% examples, 184409 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:44,765 : INFO : EPOCH 13 - PROGRESS: at 13.84% examples, 267203 words/s, in_qsize 64, out_qsize 1\n",
      "2022-11-15 14:39:45,766 : INFO : EPOCH 13 - PROGRESS: at 22.77% examples, 292092 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:46,864 : INFO : EPOCH 13 - PROGRESS: at 33.08% examples, 311064 words/s, in_qsize 63, out_qsize 6\n",
      "2022-11-15 14:39:47,916 : INFO : EPOCH 13 - PROGRESS: at 42.65% examples, 321461 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:48,946 : INFO : EPOCH 13 - PROGRESS: at 51.14% examples, 322365 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:50,078 : INFO : EPOCH 13 - PROGRESS: at 60.85% examples, 324997 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:51,108 : INFO : EPOCH 13 - PROGRESS: at 70.84% examples, 331177 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:52,126 : INFO : EPOCH 13 - PROGRESS: at 78.89% examples, 329123 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:39:53,127 : INFO : EPOCH 13 - PROGRESS: at 88.57% examples, 335025 words/s, in_qsize 51, out_qsize 0\n",
      "2022-11-15 14:39:54,030 : INFO : EPOCH 13: training on 4407961 raw words (3930827 effective words) took 11.3s, 347921 effective words/s\n",
      "2022-11-15 14:39:55,065 : INFO : EPOCH 14 - PROGRESS: at 6.35% examples, 242320 words/s, in_qsize 61, out_qsize 4\n",
      "2022-11-15 14:39:56,073 : INFO : EPOCH 14 - PROGRESS: at 13.75% examples, 261526 words/s, in_qsize 64, out_qsize 5\n",
      "2022-11-15 14:39:57,089 : INFO : EPOCH 14 - PROGRESS: at 24.13% examples, 308227 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:39:58,093 : INFO : EPOCH 14 - PROGRESS: at 33.03% examples, 317287 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:39:59,100 : INFO : EPOCH 14 - PROGRESS: at 41.96% examples, 324264 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:00,147 : INFO : EPOCH 14 - PROGRESS: at 50.86% examples, 326672 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:40:01,218 : INFO : EPOCH 14 - PROGRESS: at 60.87% examples, 332279 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:02,231 : INFO : EPOCH 14 - PROGRESS: at 69.69% examples, 333377 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:03,273 : INFO : EPOCH 14 - PROGRESS: at 78.37% examples, 332976 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:04,291 : INFO : EPOCH 14 - PROGRESS: at 87.73% examples, 336381 words/s, in_qsize 55, out_qsize 0\n",
      "2022-11-15 14:40:05,288 : INFO : EPOCH 14: training on 4407961 raw words (3931725 effective words) took 11.2s, 349618 effective words/s\n",
      "2022-11-15 14:40:06,377 : INFO : EPOCH 15 - PROGRESS: at 3.26% examples, 117944 words/s, in_qsize 63, out_qsize 21\n",
      "2022-11-15 14:40:07,354 : INFO : EPOCH 15 - PROGRESS: at 15.26% examples, 288908 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:08,362 : INFO : EPOCH 15 - PROGRESS: at 23.86% examples, 303871 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:09,501 : INFO : EPOCH 15 - PROGRESS: at 33.04% examples, 305846 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:10,532 : INFO : EPOCH 15 - PROGRESS: at 43.27% examples, 323495 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:40:11,611 : INFO : EPOCH 15 - PROGRESS: at 52.50% examples, 325777 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:12,613 : INFO : EPOCH 15 - PROGRESS: at 60.82% examples, 325881 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:40:13,692 : INFO : EPOCH 15 - PROGRESS: at 69.67% examples, 325204 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:40:14,716 : INFO : EPOCH 15 - PROGRESS: at 79.54% examples, 331125 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:15,736 : INFO : EPOCH 15 - PROGRESS: at 88.88% examples, 334489 words/s, in_qsize 50, out_qsize 0\n",
      "2022-11-15 14:40:16,607 : INFO : EPOCH 15: training on 4407961 raw words (3930862 effective words) took 11.3s, 347611 effective words/s\n",
      "2022-11-15 14:40:17,634 : INFO : EPOCH 16 - PROGRESS: at 4.21% examples, 165171 words/s, in_qsize 64, out_qsize 1\n",
      "2022-11-15 14:40:18,635 : INFO : EPOCH 16 - PROGRESS: at 14.57% examples, 281199 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:19,700 : INFO : EPOCH 16 - PROGRESS: at 23.65% examples, 299164 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:20,716 : INFO : EPOCH 16 - PROGRESS: at 33.51% examples, 317948 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:21,736 : INFO : EPOCH 16 - PROGRESS: at 42.05% examples, 320488 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:22,853 : INFO : EPOCH 16 - PROGRESS: at 50.87% examples, 319929 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:23,876 : INFO : EPOCH 16 - PROGRESS: at 60.86% examples, 328478 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:40:24,932 : INFO : EPOCH 16 - PROGRESS: at 70.53% examples, 332602 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:25,957 : INFO : EPOCH 16 - PROGRESS: at 79.98% examples, 335851 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:26,967 : INFO : EPOCH 16 - PROGRESS: at 88.11% examples, 334873 words/s, in_qsize 51, out_qsize 2\n",
      "2022-11-15 14:40:27,865 : INFO : EPOCH 16: training on 4407961 raw words (3931525 effective words) took 11.2s, 349616 effective words/s\n",
      "2022-11-15 14:40:28,902 : INFO : EPOCH 17 - PROGRESS: at 5.52% examples, 207005 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:29,936 : INFO : EPOCH 17 - PROGRESS: at 14.57% examples, 275239 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:40:30,964 : INFO : EPOCH 17 - PROGRESS: at 23.91% examples, 301317 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:40:31,988 : INFO : EPOCH 17 - PROGRESS: at 32.53% examples, 309695 words/s, in_qsize 63, out_qsize 1\n",
      "2022-11-15 14:40:33,008 : INFO : EPOCH 17 - PROGRESS: at 42.01% examples, 319437 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:40:34,067 : INFO : EPOCH 17 - PROGRESS: at 50.79% examples, 322129 words/s, in_qsize 64, out_qsize 2\n",
      "2022-11-15 14:40:35,074 : INFO : EPOCH 17 - PROGRESS: at 61.55% examples, 334776 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:40:36,119 : INFO : EPOCH 17 - PROGRESS: at 70.50% examples, 335359 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:37,121 : INFO : EPOCH 17 - PROGRESS: at 79.84% examples, 338146 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:38,129 : INFO : EPOCH 17 - PROGRESS: at 88.80% examples, 340466 words/s, in_qsize 50, out_qsize 0\n",
      "2022-11-15 14:40:39,132 : INFO : EPOCH 17 - PROGRESS: at 99.77% examples, 348386 words/s, in_qsize 1, out_qsize 1\n",
      "2022-11-15 14:40:39,144 : INFO : EPOCH 17: training on 4407961 raw words (3930224 effective words) took 11.3s, 348810 effective words/s\n",
      "2022-11-15 14:40:40,165 : INFO : EPOCH 18 - PROGRESS: at 5.22% examples, 201289 words/s, in_qsize 60, out_qsize 3\n",
      "2022-11-15 14:40:41,173 : INFO : EPOCH 18 - PROGRESS: at 13.44% examples, 259248 words/s, in_qsize 64, out_qsize 0\n",
      "2022-11-15 14:40:42,184 : INFO : EPOCH 18 - PROGRESS: at 22.71% examples, 292601 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:43,186 : INFO : EPOCH 18 - PROGRESS: at 32.35% examples, 312135 words/s, in_qsize 62, out_qsize 0\n",
      "2022-11-15 14:40:44,224 : INFO : EPOCH 18 - PROGRESS: at 40.80% examples, 314650 words/s, in_qsize 61, out_qsize 0\n",
      "2022-11-15 14:40:45,231 : INFO : EPOCH 18 - PROGRESS: at 49.61% examples, 319294 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:46,237 : INFO : EPOCH 18 - PROGRESS: at 59.49% examples, 328991 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:40:47,248 : INFO : EPOCH 18 - PROGRESS: at 69.43% examples, 336166 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:48,351 : INFO : EPOCH 18 - PROGRESS: at 78.42% examples, 334191 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:49,379 : INFO : EPOCH 18 - PROGRESS: at 87.05% examples, 334496 words/s, in_qsize 56, out_qsize 2\n",
      "2022-11-15 14:40:50,379 : INFO : EPOCH 18 - PROGRESS: at 99.37% examples, 347845 words/s, in_qsize 3, out_qsize 1\n",
      "2022-11-15 14:40:50,397 : INFO : EPOCH 18: training on 4407961 raw words (3930986 effective words) took 11.2s, 349649 effective words/s\n",
      "2022-11-15 14:40:51,448 : INFO : EPOCH 19 - PROGRESS: at 5.00% examples, 187064 words/s, in_qsize 62, out_qsize 1\n",
      "2022-11-15 14:40:52,488 : INFO : EPOCH 19 - PROGRESS: at 13.95% examples, 259893 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:53,504 : INFO : EPOCH 19 - PROGRESS: at 23.86% examples, 300660 words/s, in_qsize 64, out_qsize 1\n",
      "2022-11-15 14:40:54,520 : INFO : EPOCH 19 - PROGRESS: at 32.38% examples, 306125 words/s, in_qsize 63, out_qsize 1\n",
      "2022-11-15 14:40:55,538 : INFO : EPOCH 19 - PROGRESS: at 41.04% examples, 312846 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:56,620 : INFO : EPOCH 19 - PROGRESS: at 50.65% examples, 319661 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:57,660 : INFO : EPOCH 19 - PROGRESS: at 59.52% examples, 321433 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:40:58,720 : INFO : EPOCH 19 - PROGRESS: at 68.56% examples, 323152 words/s, in_qsize 61, out_qsize 2\n",
      "2022-11-15 14:40:59,748 : INFO : EPOCH 19 - PROGRESS: at 78.42% examples, 329210 words/s, in_qsize 63, out_qsize 0\n",
      "2022-11-15 14:41:00,771 : INFO : EPOCH 19 - PROGRESS: at 87.01% examples, 330147 words/s, in_qsize 58, out_qsize 1\n",
      "2022-11-15 14:41:01,771 : INFO : EPOCH 19 - PROGRESS: at 100.00% examples, 346043 words/s, in_qsize 0, out_qsize 1\n",
      "2022-11-15 14:41:01,772 : INFO : EPOCH 19: training on 4407961 raw words (3931729 effective words) took 11.4s, 346017 effective words/s\n",
      "2022-11-15 14:41:01,773 : INFO : Word2Vec lifecycle event {'msg': 'training on 88159220 raw words (78626161 effective words) took 232.4s, 338257 effective words/s', 'datetime': '2022-11-15T14:41:01.773255', 'gensim': '4.2.0', 'python': '3.9.5 (default, Oct 31 2022, 20:02:44) \\n[GCC 11.3.0]', 'platform': 'Linux-5.15.0-52-generic-x86_64-with-glibc2.35', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78626161, 88159220)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            vector_size=300, \n",
    "            window=4, \n",
    "            min_count=2,                          \n",
    "            sg = 1, \n",
    "            hs = 0,\n",
    "            negative = 10,\n",
    "            workers= 32,\n",
    "            seed = SEED\n",
    ") \n",
    "\n",
    "model_w2v.build_vocab(tokenized_tweet, progress_per=10000)\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(features_wordvec_train), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть как работает модель Word2vec, для этого укажу слово, и модель вытянет из корпуса наиболее похожие слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eti', 0.5845963358879089),\n",
       " ('assumme', 0.5642857551574707),\n",
       " ('cabbynet', 0.5618889331817627),\n",
       " ('wikisunn', 0.5575671792030334),\n",
       " ('nsle', 0.5565122365951538),\n",
       " ('jimini', 0.5545695424079895),\n",
       " ('chllorine', 0.5499983429908752),\n",
       " ('mapfluger', 0.5456172227859497),\n",
       " ('mickwest', 0.5416241884231567),\n",
       " ('ubiq', 0.5394173860549927)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive=\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку один твит - это набор слов, то необходимо получить один вектор из набора векторов, представляющих каждое слово в отдельности. Чтобы описать целое предложение буду использовать подход с вычислением среднего для всех векторов слов, входящих в твит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для вычисления \"среднего\" вектора\n",
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v.wv.get_vector(word).reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119469, 300)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 300)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet.iloc[i], 300)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для тестовой выборки\n",
    "tokenized_tweet_test = features_wordvec_test.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39823, 300)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet_test), 300)) \n",
    "for i in range(len(tokenized_tweet_test)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet_test.iloc[i], 300)\n",
    "wordvec_df_test = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT. Создание эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = transformers.BertModel\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "pretrained_weights = 'unitary/toxic-bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# загрузка предобученной модели/токенизатора \n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применю метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными. Задам `max_len = 512`, чтобы учесть ограничение модели BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "\n",
    "tokenized = features_bert_train.apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True)\n",
    ")      \n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4500, 512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(padded.shape, attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эмбеддинги модель BERT создаёт батчами. Чтобы хватило оперативной памяти, буду получать эмбеддинги батчами по 50 элементов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf62bf92f96d408d95a11c5f8f78cea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size + 1)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица признаков\n",
    "features_bert = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3431532 ,  0.8272309 ,  1.2637869 , ..., -0.52196896,\n",
       "         0.16769446, -0.13926   ],\n",
       "       [-0.6587919 , -0.45985788,  0.66098875, ..., -0.10696445,\n",
       "         0.68867636,  0.00931725]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_bert[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **LogicticRegression для TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        'solver': trial.suggest_categorical('solver', ['liblinear']),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "        'C': trial.suggest_float('C', 0.01, 4.0, log=True),\n",
    "        'tol': trial.suggest_float('tol', 0.0001, 0.01, log=True)\n",
    "    }\n",
    "    \n",
    "    lr = LogisticRegression(**param, random_state=SEED, n_jobs=-1)\n",
    "    lr.fit(tfidf, target_tfidf_train)\n",
    "    f1 = f1_score(target_tfidf_test, lr.predict(tfidf_test))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-15 14:24:16,203]\u001b[0m A new study created in memory with name: no-name-c810e600-3140-47e8-af10-fb5bd9762189\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:16,720]\u001b[0m Trial 0 finished with value: 0.7825497900013547 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.166468352733118, 'tol': 0.009721680092828781}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:17,621]\u001b[0m Trial 1 finished with value: 0.4966048816296568 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.08371368106482249, 'tol': 0.00021892351815784044}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:18,388]\u001b[0m Trial 2 finished with value: 0.473202614379085 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.07135008525580581, 'tol': 0.009658660966472435}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:18,775]\u001b[0m Trial 3 finished with value: 0.589778534923339 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.04293766730028246, 'tol': 0.0001322332920988386}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:19,331]\u001b[0m Trial 4 finished with value: 0.7788553476301051 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.6595020995488712, 'tol': 0.00443426342050148}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:19,947]\u001b[0m Trial 5 finished with value: 0.14860259032038176 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.013264147604839252, 'tol': 0.004079151827027131}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:20,399]\u001b[0m Trial 6 finished with value: 0.7670462533389568 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.6526486025736202, 'tol': 0.005019634277580802}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:21,171]\u001b[0m Trial 7 finished with value: 0.7796147014619484 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.6092562625260638, 'tol': 0.00010569178258893635}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:22,260]\u001b[0m Trial 8 finished with value: 0.7352941176470587 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.9539151218639955, 'tol': 0.006190801678683237}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:22,714]\u001b[0m Trial 9 finished with value: 0.6959055359607422 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.12081402519166681, 'tol': 0.0005217257731508322}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:23,236]\u001b[0m Trial 10 finished with value: 0.7481993661768942 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.3396220326098417, 'tol': 0.0012685149927066414}. Best is trial 0 with value: 0.7825497900013547.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:24,171]\u001b[0m Trial 11 finished with value: 0.7826203567118145 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.596145975359142, 'tol': 0.0013885981781377975}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:24,828]\u001b[0m Trial 12 finished with value: 0.7820097244732578 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.3740035743064802, 'tol': 0.0015896975556136176}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:25,732]\u001b[0m Trial 13 finished with value: 0.782224601793602 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.8094362307734237, 'tol': 0.0005677936968900544}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:26,212]\u001b[0m Trial 14 finished with value: 0.7546521614657887 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.3951332734089359, 'tol': 0.0023319280113045216}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:27,043]\u001b[0m Trial 15 finished with value: 0.7817081371889711 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.8734278259271333, 'tol': 0.0006694641495416364}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:27,560]\u001b[0m Trial 16 finished with value: 0.7716952221757905 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.8335505568459876, 'tol': 0.002295355016607323}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:28,045]\u001b[0m Trial 17 finished with value: 0.7358545880973323 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.2530550009703771, 'tol': 0.0003532108078068815}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:29,142]\u001b[0m Trial 18 finished with value: 0.7442882249560632 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.194546631873445, 'tol': 0.009301305766383107}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:29,969]\u001b[0m Trial 19 finished with value: 0.7821649207628256 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.43552213577952, 'tol': 0.002664355909901421}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:30,534]\u001b[0m Trial 20 finished with value: 0.763090857628078 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.5270581992824368, 'tol': 0.0008118264935061299}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:31,425]\u001b[0m Trial 21 finished with value: 0.7819548872180451 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.3082577327441904, 'tol': 0.00038744476198112124}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:32,485]\u001b[0m Trial 22 finished with value: 0.782399358031296 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.9131965308084333, 'tol': 0.00020954129121614613}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:33,291]\u001b[0m Trial 23 finished with value: 0.7800299279009659 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.851770202222706, 'tol': 0.00019146258372547452}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:34,118]\u001b[0m Trial 24 finished with value: 0.7794984240098669 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.4758079628020768, 'tol': 0.00025444196648400947}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:35,044]\u001b[0m Trial 25 finished with value: 0.7823411371237459 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.8496727402386792, 'tol': 0.0012289017396603596}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:36,744]\u001b[0m Trial 26 finished with value: 0.7575844304522037 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.072859023308769, 'tol': 0.00098821235738965}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:37,375]\u001b[0m Trial 27 finished with value: 0.7765942730668142 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.1421980557754554, 'tol': 0.0019202678669489675}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:37,934]\u001b[0m Trial 28 finished with value: 0.766896164114093 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.6325468882191667, 'tol': 0.003428837495226467}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:39,079]\u001b[0m Trial 29 finished with value: 0.6059379217273955 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.17156938073226613, 'tol': 0.00022663974263842314}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:39,772]\u001b[0m Trial 30 finished with value: 0.782279848730416 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.3876830942851677, 'tol': 0.006682971259966898}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:40,775]\u001b[0m Trial 31 finished with value: 0.7819911563714325 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.67374043565627, 'tol': 0.0012992974062572946}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:41,542]\u001b[0m Trial 32 finished with value: 0.7812330989724176 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.286299744722727, 'tol': 0.0009473630888386545}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:41,914]\u001b[0m Trial 33 finished with value: 0.5526084665378536 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.03275333955602249, 'tol': 0.00036897556426555145}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:43,095]\u001b[0m Trial 34 finished with value: 0.7819689673622259 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.9423339039264644, 'tol': 0.0001718439745013353}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:44,797]\u001b[0m Trial 35 finished with value: 0.7521688837478311 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.590281538189617, 'tol': 0.001307898827833059}. Best is trial 11 with value: 0.7826203567118145.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:45,519]\u001b[0m Trial 36 finished with value: 0.783288409703504 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.5927554412694516, 'tol': 0.0028431798433244697}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:45,885]\u001b[0m Trial 37 finished with value: 0.5841889117043121 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.041620166942035686, 'tol': 0.003392380638541511}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:46,163]\u001b[0m Trial 38 finished with value: 0.41550387596899224 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.015459277730929534, 'tol': 0.009648749777285}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:47,595]\u001b[0m Trial 39 finished with value: 0.7461034231609615 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.2731268229664163, 'tol': 0.007232245950224197}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:48,136]\u001b[0m Trial 40 finished with value: 0.7730624739112287 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.9001236281184485, 'tol': 0.004421193261964988}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:48,851]\u001b[0m Trial 41 finished with value: 0.783288409703504 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.589372634126252, 'tol': 0.0016468891834330649}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:49,708]\u001b[0m Trial 42 finished with value: 0.7825383993532741 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.6929900305666927, 'tol': 0.0017887211920434767}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:50,406]\u001b[0m Trial 43 finished with value: 0.7830303030303031 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.6658849394234974, 'tol': 0.0032155799341857935}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:51,049]\u001b[0m Trial 44 finished with value: 0.7792455399700395 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.7797570782174672, 'tol': 0.0055137112929506925}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:51,811]\u001b[0m Trial 45 finished with value: 0.7825617492239169 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.5397520727730356, 'tol': 0.0029933393700059033}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:52,579]\u001b[0m Trial 46 finished with value: 0.7829018338727077 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.6430279078370735, 'tol': 0.00297399612015807}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:53,398]\u001b[0m Trial 47 finished with value: 0.7803287596793915 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.9653463564325455, 'tol': 0.002099105300840346}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:54,169]\u001b[0m Trial 48 finished with value: 0.7813340505648197 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.905137841199488, 'tol': 0.001601661961904933}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:54,524]\u001b[0m Trial 49 finished with value: 0.6629535327816677 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.07811967088725863, 'tol': 0.003606125001406785}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:55,158]\u001b[0m Trial 50 finished with value: 0.7783278327832783 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.3536374385651522, 'tol': 0.0028036147673888095}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:55,897]\u001b[0m Trial 51 finished with value: 0.7823275862068967 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.7561919786383804, 'tol': 0.0028123732232977583}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:56,608]\u001b[0m Trial 52 finished with value: 0.7817616019483156 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.1850100246898174, 'tol': 0.002393818546864566}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:57,217]\u001b[0m Trial 53 finished with value: 0.7749896021073062 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0302454306618885, 'tol': 0.001512273403055766}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:57,797]\u001b[0m Trial 54 finished with value: 0.7683251576734408 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.7240289248432101, 'tol': 0.003959906810200979}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:58,521]\u001b[0m Trial 55 finished with value: 0.7812416017199678 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.0389891770263766, 'tol': 0.003085011490638364}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:24:59,939]\u001b[0m Trial 56 finished with value: 0.7523121387283236 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.5435574880582013, 'tol': 0.0047914694272709266}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:00,649]\u001b[0m Trial 57 finished with value: 0.7829488736004317 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.537310776744386, 'tol': 0.0023398473003658727}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:01,287]\u001b[0m Trial 58 finished with value: 0.7798776342624065 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.9097024840120587, 'tol': 0.002191512192351732}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:01,890]\u001b[0m Trial 59 finished with value: 0.759317211948791 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.4739474050294068, 'tol': 0.0016144839525293582}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:02,818]\u001b[0m Trial 60 finished with value: 0.7816153742776508 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.9481851689345953, 'tol': 0.0007769775800809489}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:03,490]\u001b[0m Trial 61 finished with value: 0.7821621621621622 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.3185022155232433, 'tol': 0.002558833881868147}. Best is trial 36 with value: 0.783288409703504.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:04,183]\u001b[0m Trial 62 finished with value: 0.783463506598438 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.6137524672484314, 'tol': 0.002042289364790806}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:04,820]\u001b[0m Trial 63 finished with value: 0.7790507364975451 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.698084034507972, 'tol': 0.0020066474211644547}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:05,605]\u001b[0m Trial 64 finished with value: 0.7820013431833445 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.2015766528566436, 'tol': 0.0017601241970531633}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:06,052]\u001b[0m Trial 65 finished with value: 0.6860158311345645 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.10135341927828531, 'tol': 0.001111551040424138}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:06,619]\u001b[0m Trial 66 finished with value: 0.776255707762557 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.1310797471970926, 'tol': 0.003948793006070198}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:07,260]\u001b[0m Trial 67 finished with value: 0.7796097829073921 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.3848446116660702, 'tol': 0.0014187448515362295}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:09,250]\u001b[0m Trial 68 finished with value: 0.7660112359550563 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.2889693341305377, 'tol': 0.0010973693032712505}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:10,040]\u001b[0m Trial 69 finished with value: 0.7801168002173028 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.9664038268443471, 'tol': 0.002463319342473071}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:10,607]\u001b[0m Trial 70 finished with value: 0.7422260970648067 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.28747639695582006, 'tol': 0.0032406942370691695}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:11,341]\u001b[0m Trial 71 finished with value: 0.7808311899282523 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.219496638792824, 'tol': 0.002961519249587985}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:12,075]\u001b[0m Trial 72 finished with value: 0.782831691186395 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.5241225541594217, 'tol': 0.0019037286313912055}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:12,803]\u001b[0m Trial 73 finished with value: 0.78324127711168 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.6163308169118067, 'tol': 0.001846429144939796}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:13,548]\u001b[0m Trial 74 finished with value: 0.7831828594529039 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.606464054569891, 'tol': 0.0018222543109999642}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:14,375]\u001b[0m Trial 75 finished with value: 0.7818765036086607 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.979476137658612, 'tol': 0.0021786446408214592}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:15,048]\u001b[0m Trial 76 finished with value: 0.7782632441288913 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.6661004426641153, 'tol': 0.001744293749577219}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:15,824]\u001b[0m Trial 77 finished with value: 0.782211473868064 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.336489520447011, 'tol': 0.0025123473996310304}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:16,595]\u001b[0m Trial 78 finished with value: 0.7821289193917372 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.777928064656222, 'tol': 0.005333625121901613}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:17,891]\u001b[0m Trial 79 finished with value: 0.7286589923755419 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.8056437254295934, 'tol': 0.0038191534021699705}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:18,625]\u001b[0m Trial 80 finished with value: 0.7810040705563094 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.0663160610924303, 'tol': 0.002016723054372088}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:19,406]\u001b[0m Trial 81 finished with value: 0.783101633148873 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.456769214473806, 'tol': 0.001842170909428683}. Best is trial 62 with value: 0.783463506598438.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:20,228]\u001b[0m Trial 82 finished with value: 0.7837692100296575 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.5514102655758655, 'tol': 0.0015554452120822276}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:20,867]\u001b[0m Trial 83 finished with value: 0.7787076416518041 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.4454466371343873, 'tol': 0.0014550208232810033}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:21,674]\u001b[0m Trial 84 finished with value: 0.78211535863839 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.350130308328017, 'tol': 0.0008836435765285478}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:22,630]\u001b[0m Trial 85 finished with value: 0.7821184051550544 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.4603935389687512, 'tol': 0.0011714653803878417}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:23,310]\u001b[0m Trial 86 finished with value: 0.7798177614579084 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.8361631660596327, 'tol': 0.001645825079231329}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:23,899]\u001b[0m Trial 87 finished with value: 0.7756685603436331 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.0760579196977007, 'tol': 0.0013180039063924879}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:24,353]\u001b[0m Trial 88 finished with value: 0.7124153498871331 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.15773859914179, 'tol': 0.0018494698002223596}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:25,058]\u001b[0m Trial 89 finished with value: 0.7829373650107991 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.5066713859780014, 'tol': 0.0023159471292424397}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:25,813]\u001b[0m Trial 90 finished with value: 0.781136638452237 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.078159579415538, 'tol': 0.0026029499052123333}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:26,537]\u001b[0m Trial 91 finished with value: 0.7826673866090713 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.4828934712114736, 'tol': 0.0021138490867872207}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:27,221]\u001b[0m Trial 92 finished with value: 0.7817368920200515 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.135363968217752, 'tol': 0.002293660489107534}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:28,237]\u001b[0m Trial 93 finished with value: 0.7825383993532741 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.6839109128827654, 'tol': 0.00010135570700701063}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:28,865]\u001b[0m Trial 94 finished with value: 0.7763992280121312 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.2526385379120937, 'tol': 0.0015224866874468392}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:29,493]\u001b[0m Trial 95 finished with value: 0.7790507364975451 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.6766090244731062, 'tol': 0.0027356871100834347}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:30,290]\u001b[0m Trial 96 finished with value: 0.7820598898885457 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.412825679039678, 'tol': 0.0034221710984211973}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:32,128]\u001b[0m Trial 97 finished with value: 0.7671883733929571 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.978717881254233, 'tol': 0.004520596397670322}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:32,866]\u001b[0m Trial 98 finished with value: 0.7801765105227427 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.9584936641796376, 'tol': 0.002298464508319717}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:25:33,698]\u001b[0m Trial 99 finished with value: 0.7814979158262741 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.874360392171034, 'tol': 0.0019331454201655482}. Best is trial 82 with value: 0.7837692100296575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 1min 42s, total: 4min 18s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=82, values=[0.7837692100296575], datetime_start=datetime.datetime(2022, 11, 15, 14, 25, 19, 407057), datetime_complete=datetime.datetime(2022, 11, 15, 14, 25, 20, 228719), params={'solver': 'liblinear', 'penalty': 'l1', 'C': 2.5514102655758655, 'tol': 0.0015554452120822276}, distributions={'solver': CategoricalDistribution(choices=('liblinear',)), 'penalty': CategoricalDistribution(choices=('l1', 'l2')), 'C': FloatDistribution(high=4.0, log=True, low=0.01, step=None), 'tol': FloatDistribution(high=0.01, log=True, low=0.0001, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=82, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params={'solver': 'liblinear', 'penalty': 'l1', 'C': 2.5514102655758655, 'tol': 0.0015554452120822276}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **LogicticRegression для Word2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        'solver': trial.suggest_categorical('solver', ['liblinear']),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "        'C': trial.suggest_float('C', 0.01, 4.0, log=True),\n",
    "        'tol': trial.suggest_float('tol', 0.0001, 0.01, log=True)\n",
    "    }\n",
    "    \n",
    "    lr = LogisticRegression(**param, random_state=SEED, n_jobs=-1)\n",
    "    lr.fit(wordvec_df, target_wordvec_train)\n",
    "    f1 = f1_score(target_wordvec_test, lr.predict(wordvec_df_test))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-15 14:41:22,790]\u001b[0m A new study created in memory with name: no-name-269cfc12-8be0-48b6-9a65-49e8d377a135\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:41:36,783]\u001b[0m Trial 0 finished with value: 0.6944770857814336 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.38769253038506113, 'tol': 0.0010669889836632633}. Best is trial 0 with value: 0.6944770857814336.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:41:42,227]\u001b[0m Trial 1 finished with value: 0.6956393635827932 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.24970963467529578, 'tol': 0.00022992032481155615}. Best is trial 1 with value: 0.6956393635827932.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:42:25,462]\u001b[0m Trial 2 finished with value: 0.6892554614355774 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.12957349954400027, 'tol': 0.0003023143798147587}. Best is trial 1 with value: 0.6956393635827932.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:42:35,357]\u001b[0m Trial 3 finished with value: 0.6888127513779233 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.12162922755713518, 'tol': 0.0013060425505569539}. Best is trial 1 with value: 0.6956393635827932.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:42:38,616]\u001b[0m Trial 4 finished with value: 0.6897165751595192 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.1654835835700179, 'tol': 0.0029244384000176745}. Best is trial 1 with value: 0.6956393635827932.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:42:42,800]\u001b[0m Trial 5 finished with value: 0.6970407266334604 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.41302973722918473, 'tol': 0.000676480840877182}. Best is trial 5 with value: 0.6970407266334604.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:42:48,001]\u001b[0m Trial 6 finished with value: 0.7023011942907078 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.3533482374997847, 'tol': 0.00011443714663796158}. Best is trial 6 with value: 0.7023011942907078.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:42:51,139]\u001b[0m Trial 7 finished with value: 0.6927160129755234 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.27597736961973013, 'tol': 0.0037027551518652563}. Best is trial 6 with value: 0.7023011942907078.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:43:27,190]\u001b[0m Trial 8 finished with value: 0.6832484267305964 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.08760654348298337, 'tol': 0.00048799756079071475}. Best is trial 6 with value: 0.7023011942907078.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:43:33,586]\u001b[0m Trial 9 finished with value: 0.5993100049285361 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.011828270597538174, 'tol': 0.0002979709365671305}. Best is trial 6 with value: 0.7023011942907078.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:43:38,908]\u001b[0m Trial 10 finished with value: 0.7023011942907078 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.280094597104219, 'tol': 0.00017745125270518031}. Best is trial 6 with value: 0.7023011942907078.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:43:44,200]\u001b[0m Trial 11 finished with value: 0.7024745269286753 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.973216323026096, 'tol': 0.00010345159161354684}. Best is trial 11 with value: 0.7024745269286753.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:43:49,466]\u001b[0m Trial 12 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.6564734727044144, 'tol': 0.00010105309302122329}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:43:54,725]\u001b[0m Trial 13 finished with value: 0.6999416228838297 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.1804710313129587, 'tol': 0.00010237844558029521}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:43:58,196]\u001b[0m Trial 14 finished with value: 0.6996053208595234 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.168017561737305, 'tol': 0.007482562302586776}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:03,476]\u001b[0m Trial 15 finished with value: 0.7006127808578931 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.3794866340228311, 'tol': 0.0001532268733122771}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:07,405]\u001b[0m Trial 16 finished with value: 0.6632856923313355 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.032622193182461, 'tol': 0.00039986637349930345}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:12,642]\u001b[0m Trial 17 finished with value: 0.7017186134576172 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.1796256160955085, 'tol': 0.00010068847256106518}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:16,857]\u001b[0m Trial 18 finished with value: 0.6992986557568673 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.7432021795017636, 'tol': 0.0018396751479123345}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:22,080]\u001b[0m Trial 19 finished with value: 0.6991228070175439 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6212375656247139, 'tol': 0.0006050108755502536}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:27,338]\u001b[0m Trial 20 finished with value: 0.7017186134576172 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.1500775698599557, 'tol': 0.00016338445616723426}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:32,570]\u001b[0m Trial 21 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.881532563380432, 'tol': 0.00018637268310780618}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:37,818]\u001b[0m Trial 22 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.844979604622523, 'tol': 0.00020737035778594}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:43,038]\u001b[0m Trial 23 finished with value: 0.7015294974508376 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.028102769379582, 'tol': 0.00023109131915318858}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:48,279]\u001b[0m Trial 24 finished with value: 0.7024745269286753 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.9776932255393254, 'tol': 0.00034954072707973276}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:53,425]\u001b[0m Trial 25 finished with value: 0.7011511001019963 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.789716379964736, 'tol': 0.00019623156106113088}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:44:58,655]\u001b[0m Trial 26 finished with value: 0.6994886778670563 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.8071128472997844, 'tol': 0.00014752294765926129}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:45:03,998]\u001b[0m Trial 27 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.7212762175455802, 'tol': 0.000732569573332369}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:45:08,283]\u001b[0m Trial 28 finished with value: 0.6817223727792834 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.06418183868935799, 'tol': 0.0002536027427955927}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:45:12,564]\u001b[0m Trial 29 finished with value: 0.6974223784417107 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.4469211860833762, 'tol': 0.0004505268468515255}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:45:16,915]\u001b[0m Trial 30 finished with value: 0.7005253940455343 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.3181129925936634, 'tol': 0.0009738634095062365}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:45:22,212]\u001b[0m Trial 31 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.78911758087398, 'tol': 0.000359292849797289}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:45:27,510]\u001b[0m Trial 32 finished with value: 0.7024901703800787 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.390946157899921, 'tol': 0.00013973220938686036}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:45:32,713]\u001b[0m Trial 33 finished with value: 0.7011511001019963 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.7996172033446798, 'tol': 0.00013211334248668048}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:45:38,013]\u001b[0m Trial 34 finished with value: 0.7024745269286753 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.9780312972023815, 'tol': 0.00021674795673085425}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:46:51,184]\u001b[0m Trial 35 finished with value: 0.698626132709734 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.032286959995301, 'tol': 0.0002748871449258368}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:46:56,479]\u001b[0m Trial 36 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.5507775650082576, 'tol': 0.00013465489937384707}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:48:13,335]\u001b[0m Trial 37 finished with value: 0.7003357174135162 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 1.7221084799790718, 'tol': 0.00019915436127095981}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:48:18,589]\u001b[0m Trial 38 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.8975859681497464, 'tol': 0.00013318429200971814}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:48:23,919]\u001b[0m Trial 39 finished with value: 0.7013706620005833 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.5880482129848612, 'tol': 0.00018142835774428444}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:49:29,302]\u001b[0m Trial 40 finished with value: 0.6970407266334604 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.49486847768083553, 'tol': 0.000284905364995579}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:49:34,558]\u001b[0m Trial 41 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.8697329915984437, 'tol': 0.00031655966242914816}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:49:39,815]\u001b[0m Trial 42 finished with value: 0.6961764705882353 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.2779553639890442, 'tol': 0.000127297547732528}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:49:45,078]\u001b[0m Trial 43 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.9796428394535694, 'tol': 0.00017277345974321464}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:49:50,346]\u001b[0m Trial 44 finished with value: 0.7024745269286753 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.9801686991223764, 'tol': 0.0002282172660861165}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:49:55,600]\u001b[0m Trial 45 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.5635308434720154, 'tol': 0.0005332435630534989}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:07,502]\u001b[0m Trial 46 finished with value: 0.6976472307467484 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.9318318175160241, 'tol': 0.0018187841539616238}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:10,592]\u001b[0m Trial 47 finished with value: 0.6280673616680033 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.012468457193728506, 'tol': 0.0003447477713104593}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:15,849]\u001b[0m Trial 48 finished with value: 0.7019076743847386 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.3269266453678576, 'tol': 0.0001092637068163353}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:20,064]\u001b[0m Trial 49 finished with value: 0.7022144522144522 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.144681068706427, 'tol': 0.004996952611352428}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:24,468]\u001b[0m Trial 50 finished with value: 0.7008023340627278 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.5416874546923758, 'tol': 0.0008118267238151093}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:29,723]\u001b[0m Trial 51 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.728531845166637, 'tol': 0.00021398074596727957}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:34,980]\u001b[0m Trial 52 finished with value: 0.7023011942907078 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.1744930322501723, 'tol': 0.00016268324207747636}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:40,236]\u001b[0m Trial 53 finished with value: 0.7019076743847386 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.2387415948679226, 'tol': 0.00023884689040356064}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:45,497]\u001b[0m Trial 54 finished with value: 0.7023011942907078 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.364788697564314, 'tol': 0.00011853510142442383}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:50,751]\u001b[0m Trial 55 finished with value: 0.7024901703800787 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.4682505133164505, 'tol': 0.00031189159487717883}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:50:54,887]\u001b[0m Trial 56 finished with value: 0.6916691372665282 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.15301794927067744, 'tol': 0.0004255118618191379}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:14,310]\u001b[0m Trial 57 finished with value: 0.7009045812664138 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.172600747999008, 'tol': 0.0003198744048337219}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:19,429]\u001b[0m Trial 58 finished with value: 0.7013403263403264 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.9077275206673807, 'tol': 0.00019917225014800047}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:24,641]\u001b[0m Trial 59 finished with value: 0.7008023340627278 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.401403502150006, 'tol': 0.0005377593136172706}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:28,839]\u001b[0m Trial 60 finished with value: 0.6787603930461074 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.05292319920818949, 'tol': 0.0002757287519744962}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:34,145]\u001b[0m Trial 61 finished with value: 0.7021989223824087 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.4259640169078125, 'tol': 0.00015695051053509035}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:39,364]\u001b[0m Trial 62 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.9298156092105008, 'tol': 0.00014502377938383434}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:44,592]\u001b[0m Trial 63 finished with value: 0.7019076743847386 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.4657570293161317, 'tol': 0.00010006629548175481}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:49,818]\u001b[0m Trial 64 finished with value: 0.7024745269286753 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.998415778292517, 'tol': 0.00014948244498049388}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:52:55,044]\u001b[0m Trial 65 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.6911760686587973, 'tol': 0.0001140417443502339}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:53:00,255]\u001b[0m Trial 66 finished with value: 0.7023011942907078 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.257114588594823, 'tol': 0.00018171095194101575}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:53:05,470]\u001b[0m Trial 67 finished with value: 0.7017186134576172 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.1030692977789234, 'tol': 0.00014123411661614562}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:53:10,688]\u001b[0m Trial 68 finished with value: 0.6999416228838297 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.132773694285889, 'tol': 0.0002033119466012481}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:53:15,862]\u001b[0m Trial 69 finished with value: 0.7013403263403264 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.849102639710915, 'tol': 0.00011875209318590923}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:54:30,687]\u001b[0m Trial 70 finished with value: 0.7016164263870686 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 3.5887564671645227, 'tol': 0.0002349564471225636}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:54:35,923]\u001b[0m Trial 71 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.9240940842722085, 'tol': 0.00039699493047080746}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:54:41,144]\u001b[0m Trial 72 finished with value: 0.7023011942907078 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.3675957574429187, 'tol': 0.0002702549508929808}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:54:46,358]\u001b[0m Trial 73 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.9539963422050732, 'tol': 0.0003075665044621615}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:54:51,568]\u001b[0m Trial 74 finished with value: 0.7020099038741625 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.5311828685013618, 'tol': 0.00032701588710834945}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:54:56,807]\u001b[0m Trial 75 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.950230647798001, 'tol': 0.00018227874774533577}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:02,020]\u001b[0m Trial 76 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.8136715608628893, 'tol': 0.0001791722038463438}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:07,232]\u001b[0m Trial 77 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.884515532636383, 'tol': 0.00022022105515651913}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:10,764]\u001b[0m Trial 78 finished with value: 0.6484705882352941 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.020535430748741895, 'tol': 0.00026038928200011627}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:14,999]\u001b[0m Trial 79 finished with value: 0.7022144522144522 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.967223256882983, 'tol': 0.0014123490713189532}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:19,119]\u001b[0m Trial 80 finished with value: 0.6880023816612088 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.11035498006575009, 'tol': 0.00020179028517035248}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:24,330]\u001b[0m Trial 81 finished with value: 0.7019076743847386 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.383876740671859, 'tol': 0.00022636955492947892}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:29,554]\u001b[0m Trial 82 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.9575489031984055, 'tol': 0.00037701081987275757}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:34,779]\u001b[0m Trial 83 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.8043714986864345, 'tol': 0.00016499026717815816}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:40,007]\u001b[0m Trial 84 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.881708513205496, 'tol': 0.000401444129997086}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:45,321]\u001b[0m Trial 85 finished with value: 0.7023011942907078 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.0877026451225156, 'tol': 0.00036605100911564953}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:55:50,629]\u001b[0m Trial 86 finished with value: 0.7017186134576172 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.1130003824927726, 'tol': 0.0004808735693720903}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:08,255]\u001b[0m Trial 87 finished with value: 0.7016469902346596 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 2.980537928471818, 'tol': 0.00012939593031908656}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:13,522]\u001b[0m Trial 88 finished with value: 0.7012684064732468 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.6402215990094857, 'tol': 0.0001794498174668275}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:18,908]\u001b[0m Trial 89 finished with value: 0.7019076743847386 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.464682982118247, 'tol': 0.00024352473379279696}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:24,174]\u001b[0m Trial 90 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.6056116676740078, 'tol': 0.00036549089447547015}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:29,442]\u001b[0m Trial 91 finished with value: 0.7023878858474083 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.5368957557456953, 'tol': 0.0006398292528644732}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:34,720]\u001b[0m Trial 92 finished with value: 0.7023878858474083 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.5842855121479564, 'tol': 0.0003940118993608014}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:40,006]\u001b[0m Trial 93 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.9932795823932508, 'tol': 0.0002888506774446226}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:45,669]\u001b[0m Trial 94 finished with value: 0.7025767942932013 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.8639208028238414, 'tol': 0.0002110866085125356}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:51,072]\u001b[0m Trial 95 finished with value: 0.7021121631463947 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.63476219015303, 'tol': 0.00021913726552836912}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:56,351]\u001b[0m Trial 96 finished with value: 0.696215579443381 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.2617579867121403, 'tol': 0.0001491094530693929}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:57:59,828]\u001b[0m Trial 97 finished with value: 0.6999561979851072 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.9782702350139005, 'tol': 0.009607608247168936}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:58:05,334]\u001b[0m Trial 98 finished with value: 0.7024901703800787 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 3.388922691823645, 'tol': 0.0004454260529981363}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n",
      "/home/troflianina/.pyenv/versions/3.9.5/envs/nlp/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1153: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-15 14:58:10,026]\u001b[0m Trial 99 finished with value: 0.6962397179788484 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.3121385019417225, 'tol': 0.0005639535753680172}. Best is trial 12 with value: 0.7025767942932013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 22s, sys: 1min 21s, total: 18min 43s\n",
      "Wall time: 16min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=12, values=[0.7025767942932013], datetime_start=datetime.datetime(2022, 11, 15, 14, 43, 44, 202228), datetime_complete=datetime.datetime(2022, 11, 15, 14, 43, 49, 466216), params={'solver': 'liblinear', 'penalty': 'l2', 'C': 3.6564734727044144, 'tol': 0.00010105309302122329}, distributions={'solver': CategoricalDistribution(choices=('liblinear',)), 'penalty': CategoricalDistribution(choices=('l1', 'l2')), 'C': FloatDistribution(high=4.0, log=True, low=0.01, step=None), 'tol': FloatDistribution(high=0.01, log=True, low=0.0001, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=12, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params={'solver': 'liblinear', 'penalty': 'l2', 'C': 3.6564734727044144, 'tol': 0.00010105309302122329}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучу модели логистической регрессии и CatBoost на признаках, полученных с помощью трех разных подходов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера на обучающей выборке: 0.7813524302689252\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Логистическая регрессия\"\"\"\n",
    "\n",
    "params = {\n",
    "    'solver': 'liblinear', \n",
    "    'penalty': 'l1', \n",
    "    'C': 2.5514102655758655, \n",
    "    'tol': 0.0015554452120822276\n",
    "}\n",
    "\n",
    "model_logistic_regression = LogisticRegression(**params, random_state=SEED)\n",
    "scores = cross_val_score(\n",
    "    model_logistic_regression, \n",
    "    tfidf, \n",
    "    target_tfidf_train, \n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "final_score = sum(scores) / len(scores)\n",
    " \n",
    "print(f'F1-мера на обучающей выборке: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-мера на обучающей выборке: 0.7813524302689252**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CatBoost\"\"\"\n",
    "\n",
    "model_catboost = CatBoostClassifier(\n",
    "    iterations=400, eval_metric='F1', verbose=0, random_state=SEED\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model_catboost, \n",
    "    tfidf, \n",
    "    target_tfidf_train, \n",
    "    cv=5, \n",
    "    scoring='f1'\n",
    ")\n",
    "final_score = sum(scores) / len(scores)\n",
    " \n",
    "print(f'F1-мера на обучающей выборке: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-мера на обучающей выборке: 0.7469776675913491**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера на обучающей выборке: 0.7066265008919472\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Логистическая регрессия\"\"\"\n",
    "\n",
    "params = {\n",
    "    'solver': 'liblinear', \n",
    "    'penalty': 'l2', \n",
    "    'C': 3.6564734727044144, \n",
    "    'tol': 0.00010105309302122329\n",
    "}\n",
    "\n",
    "model_logistic_regression = LogisticRegression(**params, random_state=SEED)\n",
    "scores = cross_val_score(\n",
    "    model_logistic_regression, \n",
    "    wordvec_df, \n",
    "    target_wordvec_train, \n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "final_score = sum(scores) / len(scores)\n",
    " \n",
    "print(f'F1-мера на обучающей выборке: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-мера на обучающей выборке: 0.7066265008919472**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера на обучающей выборке: 0.7529563557083792\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CatBoost\"\"\"\n",
    "\n",
    "model_catboost = CatBoostClassifier(\n",
    "    iterations=400, eval_metric='F1', verbose=0, random_state=SEED\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model_catboost, \n",
    "    wordvec_df, \n",
    "    target_wordvec_train,\n",
    "    cv=5, \n",
    "    scoring='f1'\n",
    ")\n",
    "final_score = sum(scores) / len(scores)\n",
    " \n",
    "print(f'F1-мера на обучающей выборке: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-мера на обучающей выборке: 0.7529563557083792**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера на обучающей выборке: 0.9449107743245133\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Логистическая регрессия\"\"\"\n",
    "\n",
    "model_logistic_regression = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "scores = cross_val_score(\n",
    "    model_logistic_regression, \n",
    "    features_bert, \n",
    "    target_bert_train, \n",
    "    cv=5, \n",
    "    scoring='f1'\n",
    ")\n",
    "final_score = sum(scores) / len(scores)\n",
    " \n",
    "print(f'F1-мера на обучающей выборке: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-мера на обучающей выборке: 0.9449107743245133**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера на обучающей выборке: 0.9479702805416708\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CatBoost\"\"\"\n",
    "\n",
    "model_catboost = CatBoostClassifier(\n",
    "    iterations=400, eval_metric='F1', verbose=0, random_state=SEED\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model_catboost, \n",
    "    features_bert, \n",
    "    target_bert_train, \n",
    "    cv=5, \n",
    "    scoring='f1'\n",
    ")\n",
    "final_score = sum(scores) / len(scores)\n",
    " \n",
    "print(f'F1-мера на обучающей выборке: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-мера на обучающей выборке: 0.9479702805416708**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** по итогами оценки разных подходов представления текстовых признаков лучшим оказался метод `Bert` и обученная на данных эмбеддингах модель `CatBoost` с результатом на обучающей выборке ключевой метрики F1-меры = 0.948."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка на тесте лучшей модели и подхода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "\n",
    "tokenized = features_bert_test.apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True)\n",
    ")      \n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3f44505e7a4edc89a3daf576a9a8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size + 1)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_bert = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера на тестовой выборке: 0.9337\n",
      "CPU times: user 4min 36s, sys: 4.7 s, total: 4min 41s\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_catboost = CatBoostClassifier(\n",
    "    iterations=400, eval_metric='F1', verbose=0, random_state=SEED\n",
    ")\n",
    "\n",
    "model_catboost.fit(features_bert, target_bert_train)\n",
    "predicted = model_catboost.predict(features_test_bert)\n",
    "score = f1_score(predicted, target_bert_test)\n",
    " \n",
    "print(f'F1-мера на тестовой выборке: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-мера на тестовой выборке: 0.9337**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучила модели машинного обучения на признаках, полученных тремя разными способами:\n",
    "- TF-IDF;\n",
    "- Word2vec;\n",
    "- BERT.\n",
    "\n",
    "Лучшим стал способ получения эмбеддингов с помощью **BERT-модели** для определения токсичности текста. По полученным эмбеддингам я обучила модели из классического ML, лучшей стала модель **CatBoost с результатом F1-меры на обучающей выборке - 0.948 и на тесте - 0.9337**."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 6653,
    "start_time": "2022-11-07T08:25:49.215Z"
   },
   {
    "duration": 13069,
    "start_time": "2022-11-07T08:26:11.941Z"
   },
   {
    "duration": 6454,
    "start_time": "2022-11-07T08:27:00.658Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T08:27:09.958Z"
   },
   {
    "duration": 4657,
    "start_time": "2022-11-07T08:27:10.975Z"
   },
   {
    "duration": 12,
    "start_time": "2022-11-07T08:27:16.615Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-07T08:27:19.104Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-07T08:27:26.414Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-07T08:27:38.422Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-07T08:27:39.719Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-07T08:27:41.191Z"
   },
   {
    "duration": 2190,
    "start_time": "2022-11-07T08:32:34.523Z"
   },
   {
    "duration": 13125,
    "start_time": "2022-11-07T08:32:58.738Z"
   },
   {
    "duration": 39045,
    "start_time": "2022-11-07T08:34:26.714Z"
   },
   {
    "duration": 13860,
    "start_time": "2022-11-07T08:56:46.011Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-07T08:56:59.874Z"
   },
   {
    "duration": 4133,
    "start_time": "2022-11-07T08:56:59.878Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-07T08:57:04.012Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-07T08:57:04.025Z"
   },
   {
    "duration": 12,
    "start_time": "2022-11-07T08:57:04.038Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-07T08:57:04.052Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-07T08:57:04.063Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-07T08:57:04.070Z"
   },
   {
    "duration": 2057,
    "start_time": "2022-11-07T08:57:11.164Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T08:57:14.517Z"
   },
   {
    "duration": 14391,
    "start_time": "2022-11-07T08:57:16.083Z"
   },
   {
    "duration": 364,
    "start_time": "2022-11-07T08:58:24.476Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-07T08:58:50.702Z"
   },
   {
    "duration": 120,
    "start_time": "2022-11-07T08:58:56.372Z"
   },
   {
    "duration": 4776,
    "start_time": "2022-11-07T09:05:29.858Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-07T09:05:34.636Z"
   },
   {
    "duration": 901,
    "start_time": "2022-11-07T09:05:34.642Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-07T09:05:35.545Z"
   },
   {
    "duration": 18,
    "start_time": "2022-11-07T09:05:35.556Z"
   },
   {
    "duration": 12,
    "start_time": "2022-11-07T09:05:35.575Z"
   },
   {
    "duration": 21,
    "start_time": "2022-11-07T09:05:35.588Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-07T09:05:35.611Z"
   },
   {
    "duration": 22,
    "start_time": "2022-11-07T09:05:35.616Z"
   },
   {
    "duration": 1860,
    "start_time": "2022-11-07T09:05:42.073Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T09:05:54.429Z"
   },
   {
    "duration": 7183,
    "start_time": "2022-11-07T09:05:58.316Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T09:06:05.589Z"
   },
   {
    "duration": 350,
    "start_time": "2022-11-07T09:06:10.415Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-07T09:11:17.551Z"
   },
   {
    "duration": 4627,
    "start_time": "2022-11-07T09:16:32.127Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T09:16:36.757Z"
   },
   {
    "duration": 852,
    "start_time": "2022-11-07T09:16:36.762Z"
   },
   {
    "duration": 16,
    "start_time": "2022-11-07T09:16:37.617Z"
   },
   {
    "duration": 14,
    "start_time": "2022-11-07T09:16:37.636Z"
   },
   {
    "duration": 18,
    "start_time": "2022-11-07T09:16:37.653Z"
   },
   {
    "duration": 12,
    "start_time": "2022-11-07T09:16:37.674Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-07T09:16:37.689Z"
   },
   {
    "duration": 43,
    "start_time": "2022-11-07T09:16:37.696Z"
   },
   {
    "duration": 2035,
    "start_time": "2022-11-07T09:16:48.131Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-07T09:16:53.578Z"
   },
   {
    "duration": 7954,
    "start_time": "2022-11-07T09:16:55.216Z"
   },
   {
    "duration": 338,
    "start_time": "2022-11-07T09:17:05.970Z"
   },
   {
    "duration": 1789,
    "start_time": "2022-11-07T09:17:21.873Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-07T09:17:25.082Z"
   },
   {
    "duration": 8512,
    "start_time": "2022-11-07T09:17:28.882Z"
   },
   {
    "duration": 62,
    "start_time": "2022-11-07T09:17:39.769Z"
   },
   {
    "duration": 47,
    "start_time": "2022-11-07T09:18:44.263Z"
   },
   {
    "duration": 46,
    "start_time": "2022-11-07T09:18:49.957Z"
   },
   {
    "duration": 24,
    "start_time": "2022-11-07T09:22:00.487Z"
   },
   {
    "duration": 56,
    "start_time": "2022-11-07T09:26:53.669Z"
   },
   {
    "duration": 11359,
    "start_time": "2022-11-07T09:27:01.092Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-07T09:27:12.454Z"
   },
   {
    "duration": 3994,
    "start_time": "2022-11-07T09:27:12.458Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-07T09:27:16.454Z"
   },
   {
    "duration": 17,
    "start_time": "2022-11-07T09:27:16.464Z"
   },
   {
    "duration": 16,
    "start_time": "2022-11-07T09:27:16.483Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-07T09:27:16.501Z"
   },
   {
    "duration": 16,
    "start_time": "2022-11-07T09:27:16.517Z"
   },
   {
    "duration": 22,
    "start_time": "2022-11-07T09:27:16.538Z"
   },
   {
    "duration": 1865,
    "start_time": "2022-11-07T09:27:19.927Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T09:27:25.143Z"
   },
   {
    "duration": 11202,
    "start_time": "2022-11-07T09:27:26.657Z"
   },
   {
    "duration": 342,
    "start_time": "2022-11-07T09:27:41.961Z"
   },
   {
    "duration": 176,
    "start_time": "2022-11-07T09:29:05.730Z"
   },
   {
    "duration": 15733,
    "start_time": "2022-11-07T10:02:10.223Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T10:02:25.959Z"
   },
   {
    "duration": 4084,
    "start_time": "2022-11-07T10:02:25.964Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-07T10:02:30.051Z"
   },
   {
    "duration": 34,
    "start_time": "2022-11-07T10:02:30.063Z"
   },
   {
    "duration": 25,
    "start_time": "2022-11-07T10:02:30.100Z"
   },
   {
    "duration": 30,
    "start_time": "2022-11-07T10:02:30.127Z"
   },
   {
    "duration": 27,
    "start_time": "2022-11-07T10:02:30.159Z"
   },
   {
    "duration": 51,
    "start_time": "2022-11-07T10:02:30.188Z"
   },
   {
    "duration": 1840,
    "start_time": "2022-11-07T10:02:34.387Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-07T10:02:37.682Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T10:02:43.075Z"
   },
   {
    "duration": 15070,
    "start_time": "2022-11-07T10:02:44.202Z"
   },
   {
    "duration": 398,
    "start_time": "2022-11-07T10:02:59.275Z"
   },
   {
    "duration": 11308,
    "start_time": "2022-11-07T10:27:28.999Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-07T10:27:40.310Z"
   },
   {
    "duration": 356,
    "start_time": "2022-11-07T10:27:40.316Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.674Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.675Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.676Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.677Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.679Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.680Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.681Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.682Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.683Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.684Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.684Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.685Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.687Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-07T10:27:40.688Z"
   },
   {
    "duration": 5112,
    "start_time": "2022-11-08T11:58:02.282Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-08T11:58:09.318Z"
   },
   {
    "duration": 3250,
    "start_time": "2022-11-08T11:58:10.963Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-08T11:58:18.324Z"
   },
   {
    "duration": 12,
    "start_time": "2022-11-08T11:58:19.867Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-08T11:58:20.963Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-08T11:58:21.939Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-08T11:58:22.640Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-08T11:58:23.315Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-08T11:58:25.643Z"
   },
   {
    "duration": 7446,
    "start_time": "2022-11-08T11:58:26.866Z"
   },
   {
    "duration": 1700,
    "start_time": "2022-11-08T11:58:36.644Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-08T11:58:52.840Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-08T11:58:55.757Z"
   },
   {
    "duration": 365,
    "start_time": "2022-11-08T11:59:04.092Z"
   },
   {
    "duration": 60,
    "start_time": "2022-11-08T12:04:16.550Z"
   },
   {
    "duration": 4007,
    "start_time": "2022-11-08T12:19:52.602Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-08T12:19:59.758Z"
   },
   {
    "duration": 868,
    "start_time": "2022-11-08T12:20:00.509Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-08T12:20:02.454Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-08T12:20:03.254Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-08T12:20:04.118Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-08T12:20:04.686Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-08T12:20:05.215Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-08T12:20:06.335Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-08T12:20:07.759Z"
   },
   {
    "duration": 6813,
    "start_time": "2022-11-08T12:20:08.886Z"
   },
   {
    "duration": 1477,
    "start_time": "2022-11-08T12:20:17.478Z"
   },
   {
    "duration": 1370,
    "start_time": "2022-11-08T12:20:20.246Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-08T12:20:22.517Z"
   },
   {
    "duration": 4178,
    "start_time": "2022-11-08T12:56:04.272Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-08T12:56:08.453Z"
   },
   {
    "duration": 2326,
    "start_time": "2022-11-08T12:56:08.459Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-08T12:56:10.787Z"
   },
   {
    "duration": 12,
    "start_time": "2022-11-08T12:56:10.800Z"
   },
   {
    "duration": 22,
    "start_time": "2022-11-08T12:56:10.814Z"
   },
   {
    "duration": 13,
    "start_time": "2022-11-08T12:56:10.838Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-08T12:56:10.853Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-08T12:56:10.860Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-08T12:56:10.873Z"
   },
   {
    "duration": 6664,
    "start_time": "2022-11-08T12:56:10.886Z"
   },
   {
    "duration": 1221,
    "start_time": "2022-11-08T12:56:17.552Z"
   },
   {
    "duration": 1086,
    "start_time": "2022-11-08T12:56:18.775Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-08T12:56:19.864Z"
   },
   {
    "duration": 1742390,
    "start_time": "2022-11-08T12:56:19.872Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-08T13:25:22.264Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-08T13:29:25.586Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-08T13:29:27.026Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-08T13:29:37.283Z"
   },
   {
    "duration": 295,
    "start_time": "2022-11-08T13:29:51.353Z"
   },
   {
    "duration": 21,
    "start_time": "2022-11-08T13:31:29.555Z"
   },
   {
    "duration": 25,
    "start_time": "2022-11-08T13:31:35.911Z"
   },
   {
    "duration": 26,
    "start_time": "2022-11-08T13:31:44.299Z"
   },
   {
    "duration": 19,
    "start_time": "2022-11-08T13:32:20.258Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-08T13:32:41.492Z"
   },
   {
    "duration": 4306,
    "start_time": "2022-11-08T13:33:00.923Z"
   },
   {
    "duration": 16264,
    "start_time": "2022-11-08T13:34:08.572Z"
   },
   {
    "duration": 6111,
    "start_time": "2022-11-08T13:34:36.324Z"
   },
   {
    "duration": 2141,
    "start_time": "2022-11-09T08:37:27.756Z"
   },
   {
    "duration": 1785,
    "start_time": "2022-11-09T08:38:44.703Z"
   },
   {
    "duration": 4254,
    "start_time": "2022-11-09T08:38:47.487Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-09T08:39:08.900Z"
   },
   {
    "duration": 3223,
    "start_time": "2022-11-09T08:39:09.724Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T08:39:12.949Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-09T08:39:12.958Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-09T08:39:14.394Z"
   },
   {
    "duration": 17,
    "start_time": "2022-11-09T08:39:15.276Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T08:39:15.818Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T08:39:16.523Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T08:39:18.060Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T08:39:18.917Z"
   },
   {
    "duration": 3250,
    "start_time": "2022-11-09T08:39:19.587Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T08:39:34.556Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T08:39:45.597Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-09T08:39:52.203Z"
   },
   {
    "duration": 4491,
    "start_time": "2022-11-09T08:46:49.060Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T08:46:55.381Z"
   },
   {
    "duration": 674,
    "start_time": "2022-11-09T08:46:57.116Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T08:46:58.512Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-09T08:46:59.232Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-09T08:47:00.088Z"
   },
   {
    "duration": 18,
    "start_time": "2022-11-09T08:47:00.647Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T08:47:01.128Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T08:47:01.638Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T08:47:03.328Z"
   },
   {
    "duration": 293,
    "start_time": "2022-11-09T08:47:04.544Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-09T08:47:21.520Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-09T08:47:35.351Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T08:47:37.432Z"
   },
   {
    "duration": 3317,
    "start_time": "2022-11-09T08:47:38.220Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-09T08:47:41.539Z"
   },
   {
    "duration": 1954,
    "start_time": "2022-11-09T09:01:04.300Z"
   },
   {
    "duration": 4235,
    "start_time": "2022-11-09T09:01:06.257Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-09T09:01:10.493Z"
   },
   {
    "duration": 659,
    "start_time": "2022-11-09T09:01:10.497Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T09:01:11.159Z"
   },
   {
    "duration": 14,
    "start_time": "2022-11-09T09:01:11.163Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-09T09:01:11.179Z"
   },
   {
    "duration": 24,
    "start_time": "2022-11-09T09:01:11.191Z"
   },
   {
    "duration": 18,
    "start_time": "2022-11-09T09:01:11.217Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T09:01:11.236Z"
   },
   {
    "duration": 294,
    "start_time": "2022-11-09T09:01:11.246Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-09T09:01:11.541Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-09T09:01:11.543Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-09T09:01:11.544Z"
   },
   {
    "duration": 0,
    "start_time": "2022-11-09T09:01:11.545Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T09:01:37.901Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-09T09:01:41.261Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-09T09:01:59.336Z"
   },
   {
    "duration": 1944,
    "start_time": "2022-11-09T09:02:42.348Z"
   },
   {
    "duration": 4249,
    "start_time": "2022-11-09T09:02:44.294Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-09T09:02:48.544Z"
   },
   {
    "duration": 694,
    "start_time": "2022-11-09T09:02:48.548Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-09T09:02:49.244Z"
   },
   {
    "duration": 13,
    "start_time": "2022-11-09T09:02:49.254Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-09T09:02:49.269Z"
   },
   {
    "duration": 21,
    "start_time": "2022-11-09T09:02:49.279Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T09:02:49.302Z"
   },
   {
    "duration": 29,
    "start_time": "2022-11-09T09:02:49.307Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T09:02:49.338Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T09:02:49.343Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T09:02:49.350Z"
   },
   {
    "duration": 3410,
    "start_time": "2022-11-09T09:02:49.358Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T09:02:52.769Z"
   },
   {
    "duration": 39,
    "start_time": "2022-11-09T09:07:12.994Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T10:48:24.140Z"
   },
   {
    "duration": 306,
    "start_time": "2022-11-09T10:49:04.437Z"
   },
   {
    "duration": 28,
    "start_time": "2022-11-09T10:49:21.684Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-09T11:12:25.261Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T11:12:39.023Z"
   },
   {
    "duration": 2035,
    "start_time": "2022-11-09T11:22:13.349Z"
   },
   {
    "duration": 4418,
    "start_time": "2022-11-09T11:22:15.386Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-09T11:22:19.806Z"
   },
   {
    "duration": 780,
    "start_time": "2022-11-09T11:22:19.810Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T11:22:20.592Z"
   },
   {
    "duration": 19,
    "start_time": "2022-11-09T11:22:20.601Z"
   },
   {
    "duration": 19,
    "start_time": "2022-11-09T11:22:20.622Z"
   },
   {
    "duration": 29,
    "start_time": "2022-11-09T11:22:20.643Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-09T11:22:20.674Z"
   },
   {
    "duration": 12,
    "start_time": "2022-11-09T11:22:20.681Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-09T11:22:20.695Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T11:22:20.712Z"
   },
   {
    "duration": 14,
    "start_time": "2022-11-09T11:22:20.722Z"
   },
   {
    "duration": 3620,
    "start_time": "2022-11-09T11:22:20.740Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T11:22:24.361Z"
   },
   {
    "duration": 43,
    "start_time": "2022-11-09T11:22:24.370Z"
   },
   {
    "duration": 18,
    "start_time": "2022-11-09T11:22:48.758Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T11:22:53.756Z"
   },
   {
    "duration": 346,
    "start_time": "2022-11-09T11:24:58.165Z"
   },
   {
    "duration": 17,
    "start_time": "2022-11-09T11:25:07.807Z"
   },
   {
    "duration": 101964,
    "start_time": "2022-11-09T11:25:17.693Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-09T11:28:08.819Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T11:29:26.024Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T11:31:55.114Z"
   },
   {
    "duration": 37,
    "start_time": "2022-11-09T11:32:32.321Z"
   },
   {
    "duration": 1858,
    "start_time": "2022-11-09T11:41:12.856Z"
   },
   {
    "duration": 4266,
    "start_time": "2022-11-09T11:41:14.716Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-09T11:41:18.984Z"
   },
   {
    "duration": 721,
    "start_time": "2022-11-09T11:41:18.988Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T11:41:19.711Z"
   },
   {
    "duration": 17,
    "start_time": "2022-11-09T11:41:19.720Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-09T11:41:19.738Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T11:41:19.748Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-09T11:41:19.754Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T11:41:19.768Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T11:41:19.772Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T11:41:32.371Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T11:41:33.509Z"
   },
   {
    "duration": 79074,
    "start_time": "2022-11-09T11:41:34.990Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-09T11:42:54.066Z"
   },
   {
    "duration": 50,
    "start_time": "2022-11-09T11:42:54.074Z"
   },
   {
    "duration": 947,
    "start_time": "2022-11-09T11:42:54.126Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T11:42:55.074Z"
   },
   {
    "duration": 1873,
    "start_time": "2022-11-09T12:07:18.019Z"
   },
   {
    "duration": 4430,
    "start_time": "2022-11-09T12:07:19.894Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T12:07:24.325Z"
   },
   {
    "duration": 725,
    "start_time": "2022-11-09T12:07:24.330Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T12:07:25.057Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-09T12:07:25.066Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-09T12:07:25.082Z"
   },
   {
    "duration": 24,
    "start_time": "2022-11-09T12:07:25.094Z"
   },
   {
    "duration": 18,
    "start_time": "2022-11-09T12:07:25.120Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T12:07:25.142Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T12:07:25.148Z"
   },
   {
    "duration": 21,
    "start_time": "2022-11-09T12:07:25.157Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-09T12:07:25.180Z"
   },
   {
    "duration": 6259,
    "start_time": "2022-11-09T12:07:25.188Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T12:07:31.448Z"
   },
   {
    "duration": 50,
    "start_time": "2022-11-09T12:07:31.457Z"
   },
   {
    "duration": 43,
    "start_time": "2022-11-09T12:07:31.508Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T12:07:31.552Z"
   },
   {
    "duration": 292686,
    "start_time": "2022-11-09T12:07:31.560Z"
   },
   {
    "duration": 87,
    "start_time": "2022-11-09T12:12:24.248Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T12:16:30.914Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T12:16:44.235Z"
   },
   {
    "duration": 319,
    "start_time": "2022-11-09T12:16:45.770Z"
   },
   {
    "duration": 1889,
    "start_time": "2022-11-09T14:00:36.026Z"
   },
   {
    "duration": 4469,
    "start_time": "2022-11-09T14:00:37.917Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T14:00:42.390Z"
   },
   {
    "duration": 959,
    "start_time": "2022-11-09T14:00:42.394Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T14:00:43.355Z"
   },
   {
    "duration": 15,
    "start_time": "2022-11-09T14:00:43.363Z"
   },
   {
    "duration": 16,
    "start_time": "2022-11-09T14:00:43.380Z"
   },
   {
    "duration": 24,
    "start_time": "2022-11-09T14:00:43.397Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T14:00:43.422Z"
   },
   {
    "duration": 6,
    "start_time": "2022-11-09T14:00:43.429Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T14:00:43.437Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T14:00:43.447Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T14:00:43.453Z"
   },
   {
    "duration": 6585,
    "start_time": "2022-11-09T14:00:43.458Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-09T14:00:50.045Z"
   },
   {
    "duration": 53,
    "start_time": "2022-11-09T14:00:50.056Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-09T14:00:50.112Z"
   },
   {
    "duration": 386,
    "start_time": "2022-11-09T14:00:50.135Z"
   },
   {
    "duration": 1888,
    "start_time": "2022-11-09T14:02:38.451Z"
   },
   {
    "duration": 4389,
    "start_time": "2022-11-09T14:02:40.342Z"
   },
   {
    "duration": 2,
    "start_time": "2022-11-09T14:02:44.733Z"
   },
   {
    "duration": 708,
    "start_time": "2022-11-09T14:02:44.737Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T14:02:45.447Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-09T14:02:45.456Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-09T14:02:45.468Z"
   },
   {
    "duration": 23,
    "start_time": "2022-11-09T14:02:45.479Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T14:02:45.504Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-09T14:02:45.536Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-09T14:02:45.541Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T14:02:45.551Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T14:02:45.558Z"
   },
   {
    "duration": 6380,
    "start_time": "2022-11-09T14:02:45.564Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-09T14:02:51.946Z"
   },
   {
    "duration": 583,
    "start_time": "2022-11-09T14:02:51.954Z"
   },
   {
    "duration": 318,
    "start_time": "2022-11-09T14:03:15.222Z"
   },
   {
    "duration": 20,
    "start_time": "2022-11-09T14:05:42.495Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T14:05:46.286Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-09T14:07:56.641Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-09T14:07:57.096Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-09T14:08:00.737Z"
   },
   {
    "duration": 251,
    "start_time": "2022-11-09T14:08:14.137Z"
   },
   {
    "duration": 266,
    "start_time": "2022-11-09T14:12:53.755Z"
   },
   {
    "duration": 2901,
    "start_time": "2022-11-14T12:33:00.758Z"
   },
   {
    "duration": 953,
    "start_time": "2022-11-14T12:33:05.871Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-14T12:33:08.493Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-14T12:33:09.277Z"
   },
   {
    "duration": 2300,
    "start_time": "2022-11-14T12:33:10.351Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-14T12:33:12.653Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-14T12:33:12.935Z"
   },
   {
    "duration": 11,
    "start_time": "2022-11-14T12:33:14.222Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-14T12:33:15.253Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-14T12:33:15.893Z"
   },
   {
    "duration": 27,
    "start_time": "2022-11-14T12:33:16.989Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-14T12:33:17.942Z"
   },
   {
    "duration": 17,
    "start_time": "2022-11-14T12:33:19.886Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-14T12:34:00.792Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-14T12:34:02.519Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-14T12:34:55.992Z"
   },
   {
    "duration": 415,
    "start_time": "2022-11-14T12:34:59.023Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-14T12:35:42.423Z"
   },
   {
    "duration": 374,
    "start_time": "2022-11-14T12:35:45.206Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-14T12:37:14.326Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-14T12:37:14.911Z"
   },
   {
    "duration": 104749,
    "start_time": "2022-11-14T12:37:15.568Z"
   },
   {
    "duration": 3403,
    "start_time": "2022-11-14T13:24:58.961Z"
   },
   {
    "duration": 298,
    "start_time": "2022-11-14T13:25:02.367Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-14T13:25:02.667Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-14T13:25:02.672Z"
   },
   {
    "duration": 871,
    "start_time": "2022-11-14T13:25:02.684Z"
   },
   {
    "duration": 9,
    "start_time": "2022-11-14T13:25:03.557Z"
   },
   {
    "duration": 20,
    "start_time": "2022-11-14T13:25:03.568Z"
   },
   {
    "duration": 12,
    "start_time": "2022-11-14T13:25:03.589Z"
   },
   {
    "duration": 10,
    "start_time": "2022-11-14T13:25:03.603Z"
   },
   {
    "duration": 35,
    "start_time": "2022-11-14T13:25:03.614Z"
   },
   {
    "duration": 51,
    "start_time": "2022-11-14T13:25:03.651Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-14T13:25:03.704Z"
   },
   {
    "duration": 20,
    "start_time": "2022-11-14T13:25:03.714Z"
   },
   {
    "duration": 3,
    "start_time": "2022-11-14T13:25:03.738Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-14T13:25:03.742Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-14T13:25:03.752Z"
   },
   {
    "duration": 13,
    "start_time": "2022-11-14T13:25:03.761Z"
   },
   {
    "duration": 103271,
    "start_time": "2022-11-14T13:25:03.775Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-14T13:26:47.048Z"
   },
   {
    "duration": 24,
    "start_time": "2022-11-14T13:26:47.057Z"
   },
   {
    "duration": 26,
    "start_time": "2022-11-14T13:26:47.083Z"
   },
   {
    "duration": 51,
    "start_time": "2022-11-14T13:26:47.112Z"
   },
   {
    "duration": 33,
    "start_time": "2022-11-14T13:26:47.165Z"
   },
   {
    "duration": 7,
    "start_time": "2022-11-14T13:26:47.200Z"
   },
   {
    "duration": 23,
    "start_time": "2022-11-14T13:26:47.209Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-14T13:28:06.035Z"
   },
   {
    "duration": 5,
    "start_time": "2022-11-14T13:28:38.242Z"
   },
   {
    "duration": 3888,
    "start_time": "2022-11-14T13:29:37.082Z"
   },
   {
    "duration": 4,
    "start_time": "2022-11-14T13:29:40.972Z"
   },
   {
    "duration": 840,
    "start_time": "2022-11-14T13:43:50.537Z"
   },
   {
    "duration": 8,
    "start_time": "2022-11-14T13:43:52.674Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
